{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d8f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2b0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mask R-CNN\n",
    "Base Configurations class.\n",
    "\n",
    "Copyright (c) 2017 Matterport, Inc.\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "Written by Waleed Abdulla\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Base Configuration Class\n",
    "# Don't use this class directly. Instead, sub-class it and override\n",
    "# the configurations you need to change.\n",
    "\n",
    "class Config(object):\n",
    "    \"\"\"Base configuration class. For custom configurations, create a\n",
    "    sub-class that inherits from this one and override properties\n",
    "    that need to be changed.\n",
    "    \"\"\"\n",
    "    # Name the configurations. For example, 'COCO', 'Experiment 3', ...etc.\n",
    "    # Useful if your code needs to do things differently depending on which\n",
    "    # experiment is running.\n",
    "    NAME = None  # Override in sub-classes\n",
    "\n",
    "    # NUMBER OF GPUs to use. When using only a CPU, this needs to be set to 1.\n",
    "    GPU_COUNT = 1\n",
    "\n",
    "    # Number of images to train with on each GPU. A 12GB GPU can typically\n",
    "    # handle 2 images of 1024x1024px.\n",
    "    # Adjust based on your GPU memory and image sizes. Use the highest\n",
    "    # number that your GPU can handle for best performance.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    # This doesn't need to match the size of the training set. Tensorboard\n",
    "    # updates are saved at the end of each epoch, so setting this to a\n",
    "    # smaller number means getting more frequent TensorBoard updates.\n",
    "    # Validation stats are also calculated at each epoch end and they\n",
    "    # might take a while, so don't set this too small to avoid spending\n",
    "    # a lot of time on validation stats.\n",
    "    STEPS_PER_EPOCH = 10\n",
    "\n",
    "    # Number of validation steps to run at the end of every training epoch.\n",
    "    # A bigger number improves accuracy of validation stats, but slows\n",
    "    # down the training.\n",
    "    VALIDATION_STEPS = 50\n",
    "\n",
    "    # Backbone network architecture\n",
    "    # Supported values are: resnet50, resnet101.\n",
    "    # You can also provide a callable that should have the signature\n",
    "    # of model.resnet_graph. If you do so, you need to supply a callable\n",
    "    # to COMPUTE_BACKBONE_SHAPE as well\n",
    "    BACKBONE = \"resnet101\"\n",
    "\n",
    "    # Only useful if you supply a callable to BACKBONE. Should compute\n",
    "    # the shape of each layer of the FPN Pyramid.\n",
    "    # See model.compute_backbone_shapes\n",
    "    COMPUTE_BACKBONE_SHAPE = None\n",
    "\n",
    "    # The strides of each layer of the FPN Pyramid. These values\n",
    "    # are based on a Resnet101 backbone.\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
    "\n",
    "    # Size of the fully-connected layers in the classification graph\n",
    "    FPN_CLASSIF_FC_LAYERS_SIZE = 1024\n",
    "\n",
    "    # Size of the top-down layers used to build the feature pyramid\n",
    "    TOP_DOWN_PYRAMID_SIZE = 256\n",
    "\n",
    "    # Number of classification classes (including background)\n",
    "    NUM_CLASSES = 1 + 6 # Override in sub-classes\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "\n",
    "    # Ratios of anchors at each cell (width/height)\n",
    "    # A value of 1 represents a square anchor, and 0.5 is a wide anchor\n",
    "    RPN_ANCHOR_RATIOS = [0.5, 1, 2]\n",
    "\n",
    "    # Anchor stride\n",
    "    # If 1 then anchors are created for each cell in the backbone feature map.\n",
    "    # If 2, then anchors are created for every other cell, and so on.\n",
    "    RPN_ANCHOR_STRIDE = 1\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.7\n",
    "\n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    \n",
    "    # ROIs kept after tf.nn.top_k and before non-maximum suppression\n",
    "    PRE_NMS_LIMIT = 6000\n",
    "\n",
    "    # ROIs kept after non-maximum suppression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 1000\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "\n",
    "    # Input image resizing\n",
    "    # Generally, use the \"square\" resizing mode for training and predicting\n",
    "    # and it should work well in most cases. In this mode, images are scaled\n",
    "    # up such that the small side is = IMAGE_MIN_DIM, but ensuring that the\n",
    "    # scaling doesn't make the long side > IMAGE_MAX_DIM. Then the image is\n",
    "    # padded with zeros to make it a square so multiple images can be put\n",
    "    # in one batch.\n",
    "    # Available resizing modes:\n",
    "    # none:   No resizing or padding. Return the image unchanged.\n",
    "    # square: Resize and pad with zeros to get a square image\n",
    "    #         of size [max_dim, max_dim].\n",
    "    # pad64:  Pads width and height with zeros to make them multiples of 64.\n",
    "    #         If IMAGE_MIN_DIM or IMAGE_MIN_SCALE are not None, then it scales\n",
    "    #         up before padding. IMAGE_MAX_DIM is ignored in this mode.\n",
    "    #         The multiple of 64 is needed to ensure smooth scaling of feature\n",
    "    #         maps up and down the 6 levels of the FPN pyramid (2**6=64).\n",
    "    # crop:   Picks random crops from the image. First, scales the image based\n",
    "    #         on IMAGE_MIN_DIM and IMAGE_MIN_SCALE, then picks a random crop of\n",
    "    #         size IMAGE_MIN_DIM x IMAGE_MIN_DIM. Can be used in training only.\n",
    "    #         IMAGE_MAX_DIM is not used in this mode.\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_MIN_DIM = 800\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    # Minimum scaling ratio. Checked after MIN_IMAGE_DIM and can force further\n",
    "    # up scaling. For example, if set to 2 then images are scaled up to double\n",
    "    # the width and height, or more, even if MIN_IMAGE_DIM doesn't require it.\n",
    "    # However, in 'square' mode, it can be overruled by IMAGE_MAX_DIM.\n",
    "    IMAGE_MIN_SCALE = 0\n",
    "    # Number of color channels per image. RGB = 3, grayscale = 1, RGB-D = 4\n",
    "    # Changing this requires other changes in the code. See the WIKI for more\n",
    "    # details: https://github.com/matterport/Mask_RCNN/wiki\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "\n",
    "    # Image mean (RGB)\n",
    "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9])\n",
    "\n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "\n",
    "    # Percent of positive ROIs used to train classifier/mask heads\n",
    "    ROI_POSITIVE_RATIO = 0.33\n",
    "\n",
    "    # Pooled ROIs\n",
    "    POOL_SIZE = 7\n",
    "    MASK_POOL_SIZE = 14\n",
    "\n",
    "    # Shape of output mask\n",
    "    # To change this you also need to change the neural network mask branch\n",
    "    MASK_SHAPE = [28, 28]\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 100\n",
    "\n",
    "    # Bounding box refinement standard deviation for RPN and final detections.\n",
    "    RPN_BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])\n",
    "    BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])\n",
    "\n",
    "    # Max number of final detections\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "\n",
    "    # Minimum probability value to accept a detected instance\n",
    "    # ROIs below this threshold are skipped\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "\n",
    "    # Non-maximum suppression threshold for detection\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "\n",
    "    # Learning rate and momentum\n",
    "    # The Mask RCNN paper uses lr=0.02, but on TensorFlow it causes\n",
    "    # weights to explode. Likely due to differences in optimizer\n",
    "    # implementation.\n",
    "    LEARNING_RATE = 0.001\n",
    "    LEARNING_MOMENTUM = 0.9\n",
    "\n",
    "    # Weight decay regularization\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "\n",
    "    # Loss weights for more precise optimization.\n",
    "    # Can be used for R-CNN training setup.\n",
    "    LOSS_WEIGHTS = {\n",
    "        \"rpn_class_loss\": 1.,\n",
    "        \"rpn_bbox_loss\": 1.,\n",
    "        \"mrcnn_class_loss\": 1.,\n",
    "        \"mrcnn_bbox_loss\": 1.,\n",
    "        \"mrcnn_mask_loss\": 1.\n",
    "    }\n",
    "\n",
    "    # Use RPN ROIs or externally generated ROIs for training\n",
    "    # Keep this True for most situations. Set to False if you want to train\n",
    "    # the head branches on ROI generated by code rather than the ROIs from\n",
    "    # the RPN. For example, to debug the classifier head without having to\n",
    "    # train the RPN.\n",
    "    USE_RPN_ROIS = True\n",
    "\n",
    "    # Train or freeze batch normalization layers\n",
    "    #     None: Train BN layers. This is the normal mode\n",
    "    #     False: Freeze BN layers. Good when using a small batch size\n",
    "    #     True: (don't use). Set layer in training mode even when predicting\n",
    "    TRAIN_BN = False  # Defaulting to False since batch size is often small\n",
    "\n",
    "    # Gradient norm clipping\n",
    "    GRADIENT_CLIP_NORM = 5.0\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Set values of computed attributes.\"\"\"\n",
    "        # Effective batch size\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "\n",
    "        # Input image size\n",
    "        if self.IMAGE_RESIZE_MODE == \"crop\":\n",
    "            self.IMAGE_SHAPE = np.array([self.IMAGE_MIN_DIM, self.IMAGE_MIN_DIM,\n",
    "                self.IMAGE_CHANNEL_COUNT])\n",
    "        else:\n",
    "            self.IMAGE_SHAPE = np.array([self.IMAGE_MAX_DIM, self.IMAGE_MAX_DIM,\n",
    "                self.IMAGE_CHANNEL_COUNT])\n",
    "\n",
    "        # Image meta data length\n",
    "        # See compose_image_meta() for details\n",
    "        self.IMAGE_META_SIZE = 1 + 3 + 3 + 4 + 1 + self.NUM_CLASSES\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4280c11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                10\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not build a TypeSpec for KerasTensor(type_spec=TensorSpec(shape=(None, None, 4), dtype=tf.float32, name=None), name='tf.math.truediv/truediv:0', description=\"created by layer 'tf.math.truediv'\") of unsupported type <class 'keras.engine.keras_tensor.KerasTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4960/1479862766.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;31m# Create model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;31m# Select weights file to load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CAT\\Mask_RCNN_Customization\\mrcnn\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[0;32m   1880\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1881\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1882\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1883\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---------------------debug model built'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1884\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'KM.Model self.keras_model.losses: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CAT\\Mask_RCNN_Customization\\mrcnn\\model.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, mode, config)\u001b[0m\n\u001b[0;32m   1971\u001b[0m             \u001b[1;31m# print('config.VALIDATION_STEPS: %s' % config.VALIDATION_STEPS)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1972\u001b[0m             \u001b[1;31m# print('config.WEIGHT_DECAY: %s' % config.WEIGHT_DECAY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1973\u001b[1;33m             gt_boxes = KL.Lambda(lambda x: norm_boxes_graph(\n\u001b[0m\u001b[0;32m   1974\u001b[0m                 x, K.shape(input_image)[1:3]))(input_gt_boxes)\n\u001b[0;32m   1975\u001b[0m             \u001b[1;31m# 3. GT Masks (zero padded)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CAT\\Mask_RCNN_Customization\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;31m# tf.debugging.disable_traceback_filtering()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhhua\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\type_spec.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    922\u001b[0m         3, \"Failed to convert %r to tensor: %s\" % (type(value).__name__, e))\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m   raise TypeError(f\"Could not build a TypeSpec for {value} of \"\n\u001b[0m\u001b[0;32m    925\u001b[0m                   f\"unsupported type {type(value)}.\")\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not build a TypeSpec for KerasTensor(type_spec=TensorSpec(shape=(None, None, 4), dtype=tf.float32, name=None), name='tf.math.truediv/truediv:0', description=\"created by layer 'tf.math.truediv'\") of unsupported type <class 'keras.engine.keras_tensor.KerasTensor'>."
     ]
    }
   ],
   "source": [
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import imgaug  # https://github.com/aleju/imgaug (pip3 install imgaug)\n",
    "\n",
    "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
    "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
    "# fix for Python 3.\n",
    "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
    "# If the PR is merged then use the original repo.\n",
    "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "DEFAULT_DATASET_YEAR = \"2023\"\n",
    "coco_path = 'C:/Users/zhhua/OneDrive/Desktop/PythonProgram/CAT/COCO/annotations_trainval2017/annotations/testing/project_blimp'\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "\n",
    "class CocoConfig(Config):\n",
    "    \"\"\"Configuration for training on MS COCO.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the COCO dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"coco\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    # Uncomment to train on 8 GPUs (default is 1)\n",
    "    # GPU_COUNT = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 80  # COCO has 80 classes\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class CocoDataset(utils.Dataset):\n",
    "    def load_coco(self, dataset_dir, subset, year=DEFAULT_DATASET_YEAR, class_ids=None,\n",
    "                  class_map=None, return_coco=False, auto_download=False):\n",
    "        \"\"\"Load a subset of the COCO dataset.\n",
    "        dataset_dir: The root directory of the COCO dataset.\n",
    "        subset: What to load (train, val, minival, valminusminival)\n",
    "        year: What dataset year to load (2014, 2017) as a string, not an integer\n",
    "        class_ids: If provided, only loads images that have the given classes.\n",
    "        class_map: TODO: Not implemented yet. Supports maping classes from\n",
    "            different datasets to the same class ID.\n",
    "        return_coco: If True, returns the COCO object.\n",
    "        auto_download: Automatically download and unzip MS-COCO images and annotations\n",
    "        \"\"\"\n",
    "\n",
    "        if auto_download is True:\n",
    "            self.auto_download(dataset_dir, subset, year)\n",
    "\n",
    "        coco = COCO(\"{}/annotations/instances_{}{}.json\".format(dataset_dir, subset, year))\n",
    "        if subset == \"minival\" or subset == \"valminusminival\":\n",
    "            subset = \"val\"\n",
    "        image_dir = \"{}/{}{}\".format(dataset_dir, subset, year)\n",
    "\n",
    "        # Load all classes or a subset?\n",
    "        if not class_ids:\n",
    "            # All classes\n",
    "            class_ids = sorted(coco.getCatIds())\n",
    "\n",
    "        # All images or a subset?\n",
    "        if class_ids:\n",
    "            image_ids = []\n",
    "            for id in class_ids:\n",
    "                image_ids.extend(list(coco.getImgIds(catIds=[id])))\n",
    "            # Remove duplicates\n",
    "            image_ids = list(set(image_ids))\n",
    "        else:\n",
    "            # All images\n",
    "            image_ids = list(coco.imgs.keys())[:1500]\n",
    "\n",
    "        # Add classes\n",
    "        for i in class_ids:\n",
    "            self.add_class(\"coco\", i, coco.loadCats(i)[0][\"name\"])\n",
    "\n",
    "        # Add images\n",
    "        for i in image_ids:\n",
    "            self.add_image(\n",
    "                \"coco\", image_id=i,\n",
    "                path=os.path.join(image_dir, coco.imgs[i]['file_name']),\n",
    "                width=coco.imgs[i][\"width\"],\n",
    "                height=coco.imgs[i][\"height\"],\n",
    "                annotations=coco.loadAnns(coco.getAnnIds(\n",
    "                    imgIds=[i], catIds=class_ids, iscrowd=None)))\n",
    "        if return_coco:\n",
    "            return coco\n",
    "\n",
    "    def auto_download(self, dataDir, dataType, dataYear):\n",
    "        \"\"\"Download the COCO dataset/annotations if requested.\n",
    "        dataDir: The root directory of the COCO dataset.\n",
    "        dataType: What to load (train, val, minival, valminusminival)\n",
    "        dataYear: What dataset year to load (2014, 2017) as a string, not an integer\n",
    "        Note:\n",
    "            For 2014, use \"train\", \"val\", \"minival\", or \"valminusminival\"\n",
    "            For 2017, only \"train\" and \"val\" annotations are available\n",
    "        \"\"\"\n",
    "\n",
    "        # Setup paths and file names\n",
    "        if dataType == \"minival\" or dataType == \"valminusminival\":\n",
    "            imgDir = \"{}/{}{}\".format(dataDir, \"val\", dataYear)\n",
    "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, \"val\", dataYear)\n",
    "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(\"val\", dataYear)\n",
    "        else:\n",
    "            imgDir = \"{}/{}{}\".format(dataDir, dataType, dataYear)\n",
    "            imgZipFile = \"{}/{}{}.zip\".format(dataDir, dataType, dataYear)\n",
    "            imgURL = \"http://images.cocodataset.org/zips/{}{}.zip\".format(dataType, dataYear)\n",
    "        # print(\"Image paths:\"); print(imgDir); print(imgZipFile); print(imgURL)\n",
    "\n",
    "        # Create main folder if it doesn't exist yet\n",
    "        if not os.path.exists(dataDir):\n",
    "            os.makedirs(dataDir)\n",
    "\n",
    "        # Download images if not available locally\n",
    "        if not os.path.exists(imgDir):\n",
    "            os.makedirs(imgDir)\n",
    "            print(\"Downloading images to \" + imgZipFile + \" ...\")\n",
    "            with urllib.request.urlopen(imgURL) as resp, open(imgZipFile, 'wb') as out:\n",
    "                shutil.copyfileobj(resp, out)\n",
    "            print(\"... done downloading.\")\n",
    "            print(\"Unzipping \" + imgZipFile)\n",
    "            with zipfile.ZipFile(imgZipFile, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(dataDir)\n",
    "            print(\"... done unzipping\")\n",
    "        print(\"Will use images in \" + imgDir)\n",
    "\n",
    "        # Setup annotations data paths\n",
    "        annDir = \"{}/annotations\".format(dataDir)\n",
    "        if dataType == \"minival\":\n",
    "            annZipFile = \"{}/instances_minival2014.json.zip\".format(dataDir)\n",
    "            annFile = \"{}/instances_minival2014.json\".format(annDir)\n",
    "            annURL = \"https://dl.dropboxusercontent.com/s/o43o90bna78omob/instances_minival2014.json.zip?dl=0\"\n",
    "            unZipDir = annDir\n",
    "        elif dataType == \"valminusminival\":\n",
    "            annZipFile = \"{}/instances_valminusminival2014.json.zip\".format(dataDir)\n",
    "            annFile = \"{}/instances_valminusminival2014.json\".format(annDir)\n",
    "            annURL = \"https://dl.dropboxusercontent.com/s/s3tw5zcg7395368/instances_valminusminival2014.json.zip?dl=0\"\n",
    "            unZipDir = annDir\n",
    "        else:\n",
    "            annZipFile = \"{}/annotations_trainval{}.zip\".format(dataDir, dataYear)\n",
    "            annFile = \"{}/instances_{}{}.json\".format(annDir, dataType, dataYear)\n",
    "            annURL = \"http://images.cocodataset.org/annotations/annotations_trainval{}.zip\".format(dataYear)\n",
    "            unZipDir = dataDir\n",
    "        # print(\"Annotations paths:\"); print(annDir); print(annFile); print(annZipFile); print(annURL)\n",
    "\n",
    "        # Download annotations if not available locally\n",
    "        if not os.path.exists(annDir):\n",
    "            os.makedirs(annDir)\n",
    "        if not os.path.exists(annFile):\n",
    "            if not os.path.exists(annZipFile):\n",
    "                print(\"Downloading zipped annotations to \" + annZipFile + \" ...\")\n",
    "                with urllib.request.urlopen(annURL) as resp, open(annZipFile, 'wb') as out:\n",
    "                    shutil.copyfileobj(resp, out)\n",
    "                print(\"... done downloading.\")\n",
    "            print(\"Unzipping \" + annZipFile)\n",
    "            with zipfile.ZipFile(annZipFile, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(unZipDir)\n",
    "            print(\"... done unzipping\")\n",
    "        print(\"Will use annotations in \" + annFile)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Load instance masks for the given image.\n",
    "\n",
    "        Different datasets use different ways to store masks. This\n",
    "        function converts the different mask format to one format\n",
    "        in the form of a bitmap [height, width, instances].\n",
    "\n",
    "        Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a COCO image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"coco\":\n",
    "            return super(CocoDataset, self).load_mask(image_id)\n",
    "\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        annotations = self.image_info[image_id][\"annotations\"]\n",
    "        # Build mask of shape [height, width, instance_count] and list\n",
    "        # of class IDs that correspond to each channel of the mask.\n",
    "        for annotation in annotations:\n",
    "            class_id = self.map_source_class_id(\n",
    "                \"coco.{}\".format(annotation['category_id']))\n",
    "            if class_id:\n",
    "                m = self.annToMask(annotation, image_info[\"height\"],\n",
    "                                   image_info[\"width\"])\n",
    "                # Some objects are so small that they're less than 1 pixel area\n",
    "                # and end up rounded out. Skip those objects.\n",
    "                if m.max() < 1:\n",
    "                    continue\n",
    "                # Is it a crowd? If so, use a negative class ID.\n",
    "                if annotation['iscrowd']:\n",
    "                    # Use negative class ID for crowds\n",
    "                    class_id *= -1\n",
    "                    # For crowd masks, annToMask() sometimes returns a mask\n",
    "                    # smaller than the given dimensions. If so, resize it.\n",
    "                    if m.shape[0] != image_info[\"height\"] or m.shape[1] != image_info[\"width\"]:\n",
    "                        m = np.ones([image_info[\"height\"], image_info[\"width\"]], dtype=bool)\n",
    "                instance_masks.append(m)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        # Pack instance masks into an array\n",
    "        if class_ids:\n",
    "            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n",
    "            class_ids = np.array(class_ids, dtype=np.int32)\n",
    "            return mask, class_ids\n",
    "        else:\n",
    "            # Call super class to return an empty mask\n",
    "            return super(CocoDataset, self).load_mask(image_id)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return a link to the image in the COCO Website.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"coco\":\n",
    "            return \"http://cocodataset.org/#explore?id={}\".format(info[\"id\"])\n",
    "        else:\n",
    "            super(CocoDataset, self).image_reference(image_id)\n",
    "\n",
    "    # The following two functions are from pycocotools with a few changes.\n",
    "\n",
    "    def annToRLE(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        segm = ann['segmentation']\n",
    "        if isinstance(segm, list):\n",
    "            # polygon -- a single object might consist of multiple parts\n",
    "            # we merge all parts into one mask rle code\n",
    "            rles = maskUtils.frPyObjects(segm, height, width)\n",
    "            rle = maskUtils.merge(rles)\n",
    "        elif isinstance(segm['counts'], list):\n",
    "            # uncompressed RLE\n",
    "            rle = maskUtils.frPyObjects(segm, height, width)\n",
    "        else:\n",
    "            # rle\n",
    "            rle = ann['segmentation']\n",
    "        return rle\n",
    "\n",
    "    def annToMask(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        rle = self.annToRLE(ann, height, width)\n",
    "        m = maskUtils.decode(rle)\n",
    "        return m\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  COCO Evaluation\n",
    "############################################################\n",
    "\n",
    "def build_coco_results(dataset, image_ids, rois, class_ids, scores, masks):\n",
    "    \"\"\"Arrange resutls to match COCO specs in http://cocodataset.org/#format\n",
    "    \"\"\"\n",
    "    # If no results, return an empty list\n",
    "    if rois is None:\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for image_id in image_ids:\n",
    "        # Loop through detections\n",
    "        for i in range(rois.shape[0]):\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i]\n",
    "            bbox = np.around(rois[i], 1)\n",
    "            mask = masks[:, :, i]\n",
    "\n",
    "            result = {\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": dataset.get_source_class_id(class_id, \"coco\"),\n",
    "                \"bbox\": [bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0]],\n",
    "                \"score\": score,\n",
    "                \"segmentation\": maskUtils.encode(np.asfortranarray(mask))\n",
    "            }\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_coco(model, dataset, coco, eval_type=\"bbox\", limit=0, image_ids=None):\n",
    "    \"\"\"Runs official COCO evaluation.\n",
    "    dataset: A Dataset object with valiadtion data\n",
    "    eval_type: \"bbox\" or \"segm\" for bounding box or segmentation evaluation\n",
    "    limit: if not 0, it's the number of images to use for evaluation\n",
    "    \"\"\"\n",
    "    # Pick COCO images from the dataset\n",
    "    image_ids = image_ids or dataset.image_ids\n",
    "\n",
    "    # Limit to a subset\n",
    "    if limit:\n",
    "        image_ids = image_ids[:limit]\n",
    "\n",
    "    # Get corresponding COCO image IDs.\n",
    "    coco_image_ids = [dataset.image_info[id][\"id\"] for id in image_ids]\n",
    "\n",
    "    t_prediction = 0\n",
    "    t_start = time.time()\n",
    "\n",
    "    results = []\n",
    "    for i, image_id in enumerate(image_ids):\n",
    "        # Load image\n",
    "        image = dataset.load_image(image_id)\n",
    "\n",
    "        # Run detection\n",
    "        t = time.time()\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        t_prediction += (time.time() - t)\n",
    "\n",
    "        # Convert results to COCO format\n",
    "        # Cast masks to uint8 because COCO tools errors out on bool\n",
    "        image_results = build_coco_results(dataset, coco_image_ids[i:i + 1],\n",
    "                                           r[\"rois\"], r[\"class_ids\"],\n",
    "                                           r[\"scores\"],\n",
    "                                           r[\"masks\"].astype(np.uint8))\n",
    "        results.extend(image_results)\n",
    "\n",
    "    # Load results. This modifies results with additional attributes.\n",
    "    coco_results = coco.loadRes(results)\n",
    "\n",
    "    # Evaluate\n",
    "    cocoEval = COCOeval(coco, coco_results, eval_type)\n",
    "    cocoEval.params.imgIds = coco_image_ids\n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "\n",
    "    print(\"Prediction time: {}. Average {}/image\".format(\n",
    "        t_prediction, t_prediction / len(image_ids)))\n",
    "    print(\"Total time: \", time.time() - t_start)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "\n",
    "\n",
    "# Configurations\n",
    "config = CocoConfig()\n",
    "config.display()\n",
    "\n",
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Select weights file to load\n",
    "model_path = COCO_MODEL_PATH\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", model_path)\n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "# Train\n",
    "# Training dataset. Use the training set and 35K from the\n",
    "# validation set, as as in the Mask RCNN paper.\n",
    "dataset_train = CocoDataset()\n",
    "dataset_train.load_coco(coco_path, \"train\", year='2023')\n",
    "\n",
    "# dataset_train.load_coco(coco_path, \"valminusminival\", year='2017')\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CocoDataset()\n",
    "val_type = \"val\"\n",
    "dataset_val.load_coco(coco_path, val_type, year='2023')\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Image Augmentation\n",
    "# Right/Left flip 50% of the time\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "# *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "# Training - Stage 1\n",
    "# print(\"Training network heads\")\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE,\n",
    "#             epochs=40,\n",
    "#             layers='heads',\n",
    "#             augmentation=augmentation)\n",
    "\n",
    "# # Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "# print(\"Fine tune Resnet stage 4 and up\")\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE,\n",
    "#             epochs=120,\n",
    "#             layers='4+',\n",
    "#             augmentation=augmentation)\n",
    "\n",
    "# Training - Stage 3\n",
    "# Fine tune all layers\n",
    "# print(\"Fine tune all layers\")\n",
    "# model.train(dataset_train, dataset_val,\n",
    "#             learning_rate=config.LEARNING_RATE / 10,\n",
    "#             epochs=160,\n",
    "#             layers='all',\n",
    "#             augmentation=augmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, config, shuffle=True, augment=False, augmentation=None,\n",
    "                   random_rois=0, batch_size=1, detection_targets=False,\n",
    "                   no_augmentation_sources=None):\n",
    "    \"\"\"A generator that returns images and corresponding target class ids,\n",
    "    bounding box deltas, and masks.\n",
    "\n",
    "    dataset: The Dataset object to pick data from\n",
    "    config: The model config object\n",
    "    shuffle: If True, shuffles the samples before every epoch\n",
    "    augment: (deprecated. Use augmentation instead). If true, apply random\n",
    "        image augmentation. Currently, only horizontal flipping is offered.\n",
    "    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "    random_rois: If > 0 then generate proposals to be used to train the\n",
    "                 network classifier and mask heads. Useful if training\n",
    "                 the Mask RCNN part without the RPN.\n",
    "    batch_size: How many images to return in each call\n",
    "    detection_targets: If True, generate detection targets (class IDs, bbox\n",
    "        deltas, and masks). Typically for debugging or visualizations because\n",
    "        in trainig detection targets are generated by DetectionTargetLayer.\n",
    "    no_augmentation_sources: Optional. List of sources to exclude for\n",
    "        augmentation. A source is string that identifies a dataset and is\n",
    "        defined in the Dataset class.\n",
    "\n",
    "    Returns a Python generator. Upon calling next() on it, the\n",
    "    generator returns two lists, inputs and outputs. The contents\n",
    "    of the lists differs depending on the received arguments:\n",
    "    inputs list:\n",
    "    - images: [batch, H, W, C]\n",
    "    - image_meta: [batch, (meta data)] Image details. See compose_image_meta()\n",
    "    - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)\n",
    "    - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.\n",
    "    - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs\n",
    "    - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]\n",
    "    - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width\n",
    "                are those of the image unless use_mini_mask is True, in which\n",
    "                case they are defined in MINI_MASK_SHAPE.\n",
    "\n",
    "    outputs list: Usually empty in regular training. But if detection_targets\n",
    "        is True then the outputs list contains target class_ids, bbox deltas,\n",
    "        and masks.\n",
    "    \"\"\"\n",
    "    b = 0  # batch item index\n",
    "    image_index = -1\n",
    "    image_ids = np.copy(dataset.image_ids)\n",
    "    error_count = 0\n",
    "    no_augmentation_sources = no_augmentation_sources or []\n",
    "\n",
    "    # Anchors\n",
    "    # [anchor_count, (y1, x1, y2, x2)]\n",
    "    backbone_shapes = compute_backbone_shapes(config, config.IMAGE_SHAPE)\n",
    "    anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,\n",
    "                                             config.RPN_ANCHOR_RATIOS,\n",
    "                                             backbone_shapes,\n",
    "                                             config.BACKBONE_STRIDES,\n",
    "                                             config.RPN_ANCHOR_STRIDE)\n",
    "\n",
    "    # Keras requires a generator to run indefinitely.\n",
    "    while True:\n",
    "        try:\n",
    "            # Increment index to pick next image. Shuffle if at the start of an epoch.\n",
    "            image_index = (image_index + 1) % len(image_ids)\n",
    "            if shuffle and image_index == 0:\n",
    "                np.random.shuffle(image_ids)\n",
    "\n",
    "            # Get GT bounding boxes and masks for image.\n",
    "            image_id = image_ids[image_index]\n",
    "\n",
    "            # If the image source is not to be augmented pass None as augmentation\n",
    "            if dataset.image_info[image_id]['source'] in no_augmentation_sources:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                              augmentation=None,\n",
    "                              use_mini_mask=config.USE_MINI_MASK)\n",
    "            else:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                    load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                                augmentation=augmentation,\n",
    "                                use_mini_mask=config.USE_MINI_MASK)\n",
    "\n",
    "            # Skip images that have no instances. This can happen in cases\n",
    "            # where we train on a subset of classes and the image doesn't\n",
    "            # have any of the classes we care about.\n",
    "            if not np.any(gt_class_ids > 0):\n",
    "                continue\n",
    "\n",
    "            # RPN Targets\n",
    "            rpn_match, rpn_bbox = build_rpn_targets(image.shape, anchors,\n",
    "                                                    gt_class_ids, gt_boxes, config)\n",
    "\n",
    "            # Mask R-CNN Targets\n",
    "            if random_rois:\n",
    "                rpn_rois = generate_random_rois(\n",
    "                    image.shape, random_rois, gt_class_ids, gt_boxes)\n",
    "                if detection_targets:\n",
    "                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask =\\\n",
    "                        build_detection_targets(\n",
    "                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, config)\n",
    "\n",
    "            # Init batch arrays\n",
    "            if b == 0:\n",
    "                batch_image_meta = np.zeros(\n",
    "                    (batch_size,) + image_meta.shape, dtype=image_meta.dtype)\n",
    "                batch_rpn_match = np.zeros(\n",
    "                    [batch_size, anchors.shape[0], 1], dtype=rpn_match.dtype)\n",
    "                batch_rpn_bbox = np.zeros(\n",
    "                    [batch_size, config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4], dtype=rpn_bbox.dtype)\n",
    "                batch_images = np.zeros(\n",
    "                    (batch_size,) + image.shape, dtype=np.float32)\n",
    "                batch_gt_class_ids = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES), dtype=np.int32)\n",
    "                batch_gt_boxes = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES, 4), dtype=np.int32)\n",
    "                batch_gt_masks = np.zeros(\n",
    "                    (batch_size, gt_masks.shape[0], gt_masks.shape[1],\n",
    "                     config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)\n",
    "                if random_rois:\n",
    "                    batch_rpn_rois = np.zeros(\n",
    "                        (batch_size, rpn_rois.shape[0], 4), dtype=rpn_rois.dtype)\n",
    "                    if detection_targets:\n",
    "                        batch_rois = np.zeros(\n",
    "                            (batch_size,) + rois.shape, dtype=rois.dtype)\n",
    "                        batch_mrcnn_class_ids = np.zeros(\n",
    "                            (batch_size,) + mrcnn_class_ids.shape, dtype=mrcnn_class_ids.dtype)\n",
    "                        batch_mrcnn_bbox = np.zeros(\n",
    "                            (batch_size,) + mrcnn_bbox.shape, dtype=mrcnn_bbox.dtype)\n",
    "                        batch_mrcnn_mask = np.zeros(\n",
    "                            (batch_size,) + mrcnn_mask.shape, dtype=mrcnn_mask.dtype)\n",
    "\n",
    "            # If more instances than fits in the array, sub-sample from them.\n",
    "            if gt_boxes.shape[0] > config.MAX_GT_INSTANCES:\n",
    "                ids = np.random.choice(\n",
    "                    np.arange(gt_boxes.shape[0]), config.MAX_GT_INSTANCES, replace=False)\n",
    "                gt_class_ids = gt_class_ids[ids]\n",
    "                gt_boxes = gt_boxes[ids]\n",
    "                gt_masks = gt_masks[:, :, ids]\n",
    "\n",
    "            # Add to batch\n",
    "            batch_image_meta[b] = image_meta\n",
    "            batch_rpn_match[b] = rpn_match[:, np.newaxis]\n",
    "            batch_rpn_bbox[b] = rpn_bbox\n",
    "            batch_images[b] = mold_image(image.astype(np.float32), config)\n",
    "            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids\n",
    "            batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes\n",
    "            batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks\n",
    "            if random_rois:\n",
    "                batch_rpn_rois[b] = rpn_rois\n",
    "                if detection_targets:\n",
    "                    batch_rois[b] = rois\n",
    "                    batch_mrcnn_class_ids[b] = mrcnn_class_ids\n",
    "                    batch_mrcnn_bbox[b] = mrcnn_bbox\n",
    "                    batch_mrcnn_mask[b] = mrcnn_mask\n",
    "            b += 1\n",
    "\n",
    "            # Batch full?\n",
    "            if b >= batch_size:\n",
    "                inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,\n",
    "                          batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]\n",
    "                outputs = []\n",
    "\n",
    "                if random_rois:\n",
    "                    inputs.extend([batch_rpn_rois])\n",
    "                    if detection_targets:\n",
    "                        inputs.extend([batch_rois])\n",
    "                        # Keras requires that output and targets have the same number of dimensions\n",
    "                        batch_mrcnn_class_ids = np.expand_dims(\n",
    "                            batch_mrcnn_class_ids, -1)\n",
    "                        outputs.extend(\n",
    "                            [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])\n",
    "\n",
    "                yield inputs, outputs\n",
    "\n",
    "                # start a new batch\n",
    "                b = 0\n",
    "        except (GeneratorExit, KeyboardInterrupt):\n",
    "            raise\n",
    "        except:\n",
    "            # Log it and skip the image\n",
    "            logging.exception(\"Error processing image {}\".format(\n",
    "                dataset.image_info[image_id]))\n",
    "            error_count += 1\n",
    "            if error_count > 5:\n",
    "                raise\n",
    "\n",
    "\n",
    "def compute_backbone_shapes(config, image_shape):\n",
    "    \"\"\"Computes the width and height of each stage of the backbone network.\n",
    "\n",
    "    Returns:\n",
    "        [N, (height, width)]. Where N is the number of stages\n",
    "    \"\"\"\n",
    "    if callable(config.BACKBONE):\n",
    "        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n",
    "\n",
    "    # Currently supports ResNet only\n",
    "    assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n",
    "    return np.array(\n",
    "        [[int(math.ceil(image_shape[0] / stride)),\n",
    "            int(math.ceil(image_shape[1] / stride))]\n",
    "            for stride in config.BACKBONE_STRIDES])\n",
    "\n",
    "def load_image_gt(dataset, config, image_id, augment=False, augmentation=None,\n",
    "                  use_mini_mask=False):\n",
    "    \"\"\"Load and return ground truth data for an image (image, mask, bounding boxes).\n",
    "\n",
    "    augment: (deprecated. Use augmentation instead). If true, apply random\n",
    "        image augmentation. Currently, only horizontal flipping is offered.\n",
    "    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "    use_mini_mask: If False, returns full-size masks that are the same height\n",
    "        and width as the original image. These can be big, for example\n",
    "        1024x1024x100 (for 100 instances). Mini masks are smaller, typically,\n",
    "        224x224 and are generated by extracting the bounding box of the\n",
    "        object and resizing it to MINI_MASK_SHAPE.\n",
    "\n",
    "    Returns:\n",
    "    image: [height, width, 3]\n",
    "    shape: the original shape of the image before resizing and cropping.\n",
    "    class_ids: [instance_count] Integer class IDs\n",
    "    bbox: [instance_count, (y1, x1, y2, x2)]\n",
    "    mask: [height, width, instance_count]. The height and width are those\n",
    "        of the image unless use_mini_mask is True, in which case they are\n",
    "        defined in MINI_MASK_SHAPE.\n",
    "    \"\"\"\n",
    "    # Load image and mask\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    original_shape = image.shape\n",
    "    image, window, scale, padding, crop = utils.resize_image(\n",
    "        image,\n",
    "        min_dim=config.IMAGE_MIN_DIM,\n",
    "        min_scale=config.IMAGE_MIN_SCALE,\n",
    "        max_dim=config.IMAGE_MAX_DIM,\n",
    "        mode=config.IMAGE_RESIZE_MODE)\n",
    "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
    "\n",
    "    # Random horizontal flips.\n",
    "    # TODO: will be removed in a future update in favor of augmentation\n",
    "    if augment:\n",
    "        logging.warning(\"'augment' is deprecated. Use 'augmentation' instead.\")\n",
    "        if random.randint(0, 1):\n",
    "            image = np.fliplr(image)\n",
    "            mask = np.fliplr(mask)\n",
    "\n",
    "    # Augmentation\n",
    "    # This requires the imgaug lib (https://github.com/aleju/imgaug)\n",
    "    if augmentation:\n",
    "        import imgaug\n",
    "\n",
    "        # Augmenters that are safe to apply to masks\n",
    "        # Some, such as Affine, have settings that make them unsafe, so always\n",
    "        # test your augmentation on masks\n",
    "        MASK_AUGMENTERS = [\"Sequential\", \"SomeOf\", \"OneOf\", \"Sometimes\",\n",
    "                           \"Fliplr\", \"Flipud\", \"CropAndPad\",\n",
    "                           \"Affine\", \"PiecewiseAffine\"]\n",
    "\n",
    "        def hook(images, augmenter, parents, default):\n",
    "            \"\"\"Determines which augmenters to apply to masks.\"\"\"\n",
    "            return augmenter.__class__.__name__ in MASK_AUGMENTERS\n",
    "\n",
    "        # Store shapes before augmentation to compare\n",
    "        image_shape = image.shape\n",
    "        mask_shape = mask.shape\n",
    "        # Make augmenters deterministic to apply similarly to images and masks\n",
    "        det = augmentation.to_deterministic()\n",
    "        image = det.augment_image(image)\n",
    "        # Change mask to np.uint8 because imgaug doesn't support np.bool\n",
    "        mask = det.augment_image(mask.astype(np.uint8),\n",
    "                                 hooks=imgaug.HooksImages(activator=hook))\n",
    "        # Verify that shapes didn't change\n",
    "        assert image.shape == image_shape, \"Augmentation shouldn't change image size\"\n",
    "        assert mask.shape == mask_shape, \"Augmentation shouldn't change mask size\"\n",
    "        # Change mask back to bool\n",
    "        mask = mask.astype(np.bool)\n",
    "\n",
    "    # Note that some boxes might be all zeros if the corresponding mask got cropped out.\n",
    "    # and here is to filter them out\n",
    "    _idx = np.sum(mask, axis=(0, 1)) > 0\n",
    "    mask = mask[:, :, _idx]\n",
    "    class_ids = class_ids[_idx]\n",
    "    # Bounding boxes. Note that some boxes might be all zeros\n",
    "    # if the corresponding mask got cropped out.\n",
    "    # bbox: [num_instances, (y1, x1, y2, x2)]\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "    # Active classes\n",
    "    # Different datasets have different classes, so track the\n",
    "    # classes supported in the dataset of this image.\n",
    "    active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)\n",
    "    source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][\"source\"]]\n",
    "    active_class_ids[source_class_ids] = 1\n",
    "\n",
    "    # Resize masks to smaller size to reduce memory usage\n",
    "    if use_mini_mask:\n",
    "        mask = utils.minimize_mask(bbox, mask, config.MINI_MASK_SHAPE)\n",
    "\n",
    "    # Image meta data\n",
    "    image_meta = compose_image_meta(image_id, original_shape, image.shape,\n",
    "                                    window, scale, active_class_ids)\n",
    "\n",
    "    return image, image_meta, class_ids, bbox, mask\n",
    "\n",
    "\n",
    "def compose_image_meta(image_id, original_image_shape, image_shape,\n",
    "                       window, scale, active_class_ids):\n",
    "    \"\"\"Takes attributes of an image and puts them in one 1D array.\n",
    "\n",
    "    image_id: An int ID of the image. Useful for debugging.\n",
    "    original_image_shape: [H, W, C] before resizing or padding.\n",
    "    image_shape: [H, W, C] after resizing and padding\n",
    "    window: (y1, x1, y2, x2) in pixels. The area of the image where the real\n",
    "            image is (excluding the padding)\n",
    "    scale: The scaling factor applied to the original image (float32)\n",
    "    active_class_ids: List of class_ids available in the dataset from which\n",
    "        the image came. Useful if training on images from multiple datasets\n",
    "        where not all classes are present in all datasets.\n",
    "    \"\"\"\n",
    "    meta = np.array(\n",
    "        [image_id] +                  # size=1\n",
    "        list(original_image_shape) +  # size=3\n",
    "        list(image_shape) +           # size=3\n",
    "        list(window) +                # size=4 (y1, x1, y2, x2) in image cooredinates\n",
    "        [scale] +                     # size=1\n",
    "        list(active_class_ids)        # size=num_classes\n",
    "    )\n",
    "    return meta\n",
    "\n",
    "\n",
    "def build_rpn_targets(image_shape, anchors, gt_class_ids, gt_boxes, config):\n",
    "    \"\"\"Given the anchors and GT boxes, compute overlaps and identify positive\n",
    "    anchors and deltas to refine them to match their corresponding GT boxes.\n",
    "\n",
    "    anchors: [num_anchors, (y1, x1, y2, x2)]\n",
    "    gt_class_ids: [num_gt_boxes] Integer class IDs.\n",
    "    gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)]\n",
    "\n",
    "    Returns:\n",
    "    rpn_match: [N] (int32) matches between anchors and GT boxes.\n",
    "               1 = positive anchor, -1 = negative anchor, 0 = neutral\n",
    "    rpn_bbox: [N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.\n",
    "    \"\"\"\n",
    "    # RPN Match: 1 = positive anchor, -1 = negative anchor, 0 = neutral\n",
    "    rpn_match = np.zeros([anchors.shape[0]], dtype=np.int32)\n",
    "    # RPN bounding boxes: [max anchors per image, (dy, dx, log(dh), log(dw))]\n",
    "    rpn_bbox = np.zeros((config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4))\n",
    "\n",
    "    # Handle COCO crowds\n",
    "    # A crowd box in COCO is a bounding box around several instances. Exclude\n",
    "    # them from training. A crowd box is given a negative class ID.\n",
    "    crowd_ix = np.where(gt_class_ids < 0)[0]\n",
    "    if crowd_ix.shape[0] > 0:\n",
    "        # Filter out crowds from ground truth class IDs and boxes\n",
    "        non_crowd_ix = np.where(gt_class_ids > 0)[0]\n",
    "        crowd_boxes = gt_boxes[crowd_ix]\n",
    "        gt_class_ids = gt_class_ids[non_crowd_ix]\n",
    "        gt_boxes = gt_boxes[non_crowd_ix]\n",
    "        # Compute overlaps with crowd boxes [anchors, crowds]\n",
    "        crowd_overlaps = utils.compute_overlaps(anchors, crowd_boxes)\n",
    "        crowd_iou_max = np.amax(crowd_overlaps, axis=1)\n",
    "        no_crowd_bool = (crowd_iou_max < 0.001)\n",
    "    else:\n",
    "        # All anchors don't intersect a crowd\n",
    "        no_crowd_bool = np.ones([anchors.shape[0]], dtype=bool)\n",
    "\n",
    "    # Compute overlaps [num_anchors, num_gt_boxes]\n",
    "    overlaps = utils.compute_overlaps(anchors, gt_boxes)\n",
    "\n",
    "    # Match anchors to GT Boxes\n",
    "    # If an anchor overlaps a GT box with IoU >= 0.7 then it's positive.\n",
    "    # If an anchor overlaps a GT box with IoU < 0.3 then it's negative.\n",
    "    # Neutral anchors are those that don't match the conditions above,\n",
    "    # and they don't influence the loss function.\n",
    "    # However, don't keep any GT box unmatched (rare, but happens). Instead,\n",
    "    # match it to the closest anchor (even if its max IoU is < 0.3).\n",
    "    #\n",
    "    # 1. Set negative anchors first. They get overwritten below if a GT box is\n",
    "    # matched to them. Skip boxes in crowd areas.\n",
    "    anchor_iou_argmax = np.argmax(overlaps, axis=1)\n",
    "    anchor_iou_max = overlaps[np.arange(overlaps.shape[0]), anchor_iou_argmax]\n",
    "    rpn_match[(anchor_iou_max < 0.3) & (no_crowd_bool)] = -1\n",
    "    # 2. Set an anchor for each GT box (regardless of IoU value).\n",
    "    # If multiple anchors have the same IoU match all of them\n",
    "    gt_iou_argmax = np.argwhere(overlaps == np.max(overlaps, axis=0))[:,0]\n",
    "    rpn_match[gt_iou_argmax] = 1\n",
    "    # 3. Set anchors with high overlap as positive.\n",
    "    rpn_match[anchor_iou_max >= 0.7] = 1\n",
    "\n",
    "    # Subsample to balance positive and negative anchors\n",
    "    # Don't let positives be more than half the anchors\n",
    "    ids = np.where(rpn_match == 1)[0]\n",
    "    extra = len(ids) - (config.RPN_TRAIN_ANCHORS_PER_IMAGE // 2)\n",
    "    if extra > 0:\n",
    "        # Reset the extra ones to neutral\n",
    "        ids = np.random.choice(ids, extra, replace=False)\n",
    "        rpn_match[ids] = 0\n",
    "    # Same for negative proposals\n",
    "    ids = np.where(rpn_match == -1)[0]\n",
    "    extra = len(ids) - (config.RPN_TRAIN_ANCHORS_PER_IMAGE -\n",
    "                        np.sum(rpn_match == 1))\n",
    "    if extra > 0:\n",
    "        # Rest the extra ones to neutral\n",
    "        ids = np.random.choice(ids, extra, replace=False)\n",
    "        rpn_match[ids] = 0\n",
    "\n",
    "    # For positive anchors, compute shift and scale needed to transform them\n",
    "    # to match the corresponding GT boxes.\n",
    "    ids = np.where(rpn_match == 1)[0]\n",
    "    ix = 0  # index into rpn_bbox\n",
    "    # TODO: use box_refinement() rather than duplicating the code here\n",
    "    for i, a in zip(ids, anchors[ids]):\n",
    "        # Closest gt box (it might have IoU < 0.7)\n",
    "        gt = gt_boxes[anchor_iou_argmax[i]]\n",
    "\n",
    "        # Convert coordinates to center plus width/height.\n",
    "        # GT Box\n",
    "        gt_h = gt[2] - gt[0]\n",
    "        gt_w = gt[3] - gt[1]\n",
    "        gt_center_y = gt[0] + 0.5 * gt_h\n",
    "        gt_center_x = gt[1] + 0.5 * gt_w\n",
    "        # Anchor\n",
    "        a_h = a[2] - a[0]\n",
    "        a_w = a[3] - a[1]\n",
    "        a_center_y = a[0] + 0.5 * a_h\n",
    "        a_center_x = a[1] + 0.5 * a_w\n",
    "\n",
    "        # Compute the bbox refinement that the RPN should predict.\n",
    "        rpn_bbox[ix] = [\n",
    "            (gt_center_y - a_center_y) / a_h,\n",
    "            (gt_center_x - a_center_x) / a_w,\n",
    "            np.log(gt_h / a_h),\n",
    "            np.log(gt_w / a_w),\n",
    "        ]\n",
    "        # Normalize\n",
    "        rpn_bbox[ix] /= config.RPN_BBOX_STD_DEV\n",
    "        ix += 1\n",
    "\n",
    "    return rpn_match, rpn_bbox\n",
    "\n",
    "def mold_image(images, config):\n",
    "    \"\"\"Expects an RGB image (or array of images) and subtracts\n",
    "    the mean pixel and converts it to float. Expects image\n",
    "    colors in RGB order.\n",
    "    \"\"\"\n",
    "    return images.astype(np.float32) - config.MEAN_PIXEL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09704c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training - Stage 1\n",
    "print(\"Training network heads\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=3,\n",
    "            layers='heads',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "# # Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=3,\n",
    "            layers='4+',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "# Training - Stage 3\n",
    "# Fine tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=3,\n",
    "            layers='all',\n",
    "            augmentation=augmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d93b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keras_model.save_weights('mask_rcnn_coco_train8_customized_classes_from_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8165d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the file path from which you want to read the JSON data\n",
    "file_path = coco_path + '/annotations/instances_val2017.json'\n",
    "\n",
    "# Open the file in read mode and use json.load() to read the data\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# train dataset\n",
    "# take full info, licenses and categories\n",
    "# get 1500 images with corresponding anns\n",
    "# new_train_json = {}\n",
    "# for data_key in data:\n",
    "#     if data_key == 'info' or data_key == 'licenses' or data_key == 'categories':\n",
    "#         new_train_json[data_key] = data[data_key]\n",
    "#     elif data_key == 'images':\n",
    "#         new_train_json[data_key] = data[data_key][:1500]\n",
    "\n",
    "# new_train_anns = []\n",
    "# for image in new_train_json['images']:\n",
    "#     print('working on image id: %s' % image['id'])\n",
    "#     for ann in data['annotations']:\n",
    "#         if ann['image_id'] == image['id']:\n",
    "#             new_train_anns.append(ann)\n",
    "# new_train_json['annotations'] = new_train_anns\n",
    "\n",
    "# val dataset\n",
    "# new_val_json = {}\n",
    "# for data_key in data:\n",
    "#     if data_key == 'info' or data_key == 'licenses' or data_key == 'categories':\n",
    "#         new_val_json[data_key] = data[data_key]\n",
    "#     elif data_key == 'images':\n",
    "#         new_val_json[data_key] = data[data_key][1500:1600]\n",
    "\n",
    "# new_val_anns = []\n",
    "# for image in new_val_json['images']:\n",
    "#     print('working on image id: %s' % image['id'])\n",
    "#     for ann in data['annotations']:\n",
    "#         if ann['image_id'] == image['id']:\n",
    "#             new_val_anns.append(ann)\n",
    "# new_val_json['annotations'] = new_val_anns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1227671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the JSON data\n",
    "file_path = \"C:/Users/zhhua/OneDrive/Desktop/PythonProgram/CAT/COCO/annotations_trainval2017/annotations/testing/annotations/instances_val2017.json\"\n",
    "\n",
    "# Open the file in write mode and use json.dump() to write the data\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(new_val_json, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebbdec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on image id: 1\n",
      "working on image id: 2\n",
      "working on image id: 3\n",
      "working on image id: 4\n",
      "working on image id: 5\n",
      "working on image id: 6\n",
      "working on image id: 7\n",
      "working on image id: 8\n",
      "working on image id: 9\n",
      "working on image id: 10\n",
      "working on image id: 11\n",
      "working on image id: 12\n",
      "working on image id: 13\n",
      "working on image id: 14\n",
      "working on image id: 15\n",
      "working on image id: 16\n",
      "working on image id: 17\n",
      "working on image id: 18\n",
      "working on image id: 19\n",
      "working on image id: 20\n",
      "working on image id: 21\n",
      "working on image id: 22\n",
      "working on image id: 23\n",
      "working on image id: 24\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# train dataset\n",
    "file_path = coco_path + '/CAT_person/annotations/instances_default.json'\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    instances_default_data = json.load(json_file)\n",
    "\n",
    "# val dataset\n",
    "# file_path = coco_path + '/annotations/instances_val2017.json'\n",
    "# with open(file_path, \"r\") as json_file:\n",
    "#     val_data = json.load(json_file)\n",
    "# len(val_data['images'])\n",
    "\n",
    "\n",
    "instances_default_data\n",
    "\n",
    "\n",
    "\n",
    "# train dataset\n",
    "# take full info, licenses and categories\n",
    "# get 1500 images with corresponding anns\n",
    "new_train_json = {}\n",
    "for data_key in instances_default_data:\n",
    "    if data_key == 'info' or data_key == 'licenses' or data_key == 'categories':\n",
    "        new_train_json[data_key] = instances_default_data[data_key]\n",
    "    elif data_key == 'images':\n",
    "        new_train_json[data_key] = instances_default_data[data_key][:20]\n",
    "\n",
    "new_train_anns = []\n",
    "for image in new_train_json['images']:\n",
    "    print('working on image id: %s' % image['id'])\n",
    "    for ann in instances_default_data['annotations']:\n",
    "        if ann['image_id'] == image['id']:\n",
    "            new_train_anns.append(ann)\n",
    "new_train_json['annotations'] = new_train_anns\n",
    "\n",
    "\n",
    "\n",
    "# val dataset\n",
    "new_val_json = {}\n",
    "for data_key in instances_default_data:\n",
    "    if data_key == 'info' or data_key == 'licenses' or data_key == 'categories':\n",
    "        new_val_json[data_key] = instances_default_data[data_key]\n",
    "    elif data_key == 'images':\n",
    "        new_val_json[data_key] = instances_default_data[data_key][20:]\n",
    "\n",
    "new_val_anns = []\n",
    "for image in new_val_json['images']:\n",
    "    print('working on image id: %s' % image['id'])\n",
    "    for ann in instances_default_data['annotations']:\n",
    "        if ann['image_id'] == image['id']:\n",
    "            new_val_anns.append(ann)\n",
    "new_val_json['annotations'] = new_val_anns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "759b2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the JSON data\n",
    "file_path = \"C:/Users/zhhua/OneDrive/Desktop/PythonProgram/CAT/COCO/annotations_trainval2017/annotations/testing/CAT_person/annotations/instances_train2023.json\"\n",
    "\n",
    "# Open the file in write mode and use json.dump() to write the data\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(new_train_json, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3d61e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on image id: 325527\n",
      "working on image id: 465718\n",
      "working on image id: 285349\n",
      "working on image id: 322163\n",
      "working on image id: 346968\n",
      "working on image id: 229216\n",
      "working on image id: 563882\n",
      "working on image id: 199681\n",
      "working on image id: 313130\n",
      "working on image id: 294163\n",
      "working on image id: 176232\n",
      "working on image id: 407403\n",
      "working on image id: 562843\n",
      "working on image id: 483999\n",
      "working on image id: 58705\n",
      "working on image id: 216497\n",
      "working on image id: 323263\n",
      "working on image id: 506310\n",
      "working on image id: 248334\n",
      "working on image id: 400803\n",
      "working on image id: 422706\n",
      "working on image id: 7574\n",
      "working on image id: 542089\n",
      "working on image id: 53505\n",
      "working on image id: 500464\n",
      "working on image id: 78823\n",
      "working on image id: 527220\n",
      "working on image id: 178982\n",
      "working on image id: 332455\n",
      "working on image id: 408696\n",
      "working on image id: 144300\n",
      "working on image id: 7816\n",
      "working on image id: 152120\n",
      "working on image id: 308631\n",
      "working on image id: 517523\n",
      "working on image id: 5477\n",
      "working on image id: 15272\n",
      "working on image id: 391375\n",
      "working on image id: 442661\n",
      "working on image id: 69138\n",
      "working on image id: 104619\n",
      "working on image id: 432553\n",
      "working on image id: 548267\n",
      "working on image id: 315187\n",
      "working on image id: 76417\n",
      "working on image id: 196843\n",
      "working on image id: 138550\n",
      "working on image id: 244019\n",
      "working on image id: 439623\n",
      "working on image id: 343315\n",
      "working on image id: 46804\n",
      "working on image id: 340451\n",
      "working on image id: 480842\n",
      "working on image id: 436883\n",
      "working on image id: 546556\n",
      "working on image id: 459500\n",
      "working on image id: 98497\n",
      "working on image id: 338718\n",
      "working on image id: 228771\n",
      "working on image id: 50165\n",
      "working on image id: 158956\n",
      "working on image id: 311883\n",
      "working on image id: 270386\n",
      "working on image id: 240767\n",
      "working on image id: 100723\n",
      "working on image id: 431896\n",
      "working on image id: 129062\n",
      "working on image id: 442456\n",
      "working on image id: 79229\n",
      "working on image id: 188439\n",
      "working on image id: 151480\n",
      "working on image id: 46872\n",
      "working on image id: 219485\n",
      "working on image id: 532575\n",
      "working on image id: 489014\n",
      "working on image id: 289229\n",
      "working on image id: 281929\n",
      "working on image id: 257896\n",
      "working on image id: 203580\n",
      "working on image id: 493284\n",
      "working on image id: 28449\n",
      "working on image id: 179174\n",
      "working on image id: 393115\n",
      "working on image id: 370813\n",
      "working on image id: 442746\n",
      "working on image id: 236592\n",
      "working on image id: 116589\n",
      "working on image id: 369541\n",
      "working on image id: 122969\n",
      "working on image id: 381971\n",
      "working on image id: 236730\n",
      "working on image id: 396863\n",
      "working on image id: 576052\n",
      "working on image id: 344888\n",
      "working on image id: 51712\n",
      "working on image id: 480275\n",
      "working on image id: 282037\n",
      "working on image id: 476770\n",
      "working on image id: 220764\n",
      "working on image id: 493799\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "for image in val_data['images']:\n",
    "    print('working on image id: %s' % image['id'])\n",
    "    file_name = str(image['id'])\n",
    "    while len(file_name) != 12:\n",
    "        file_name = '0' + file_name\n",
    "\n",
    "    # Specify source and destination file paths\n",
    "    source_file = 'C:/Users/zhhua/OneDrive/Desktop/PythonProgram/CAT/COCO/val2017/val2017/%s.jpg' % file_name\n",
    "    destination_file = 'C:/Users/zhhua/OneDrive/Desktop/PythonProgram/CAT/COCO/annotations_trainval2017/annotations/testing/val2017/%s.jpg' % file_name\n",
    "\n",
    "    # Copy the file\n",
    "    shutil.copy(source_file, destination_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e661c0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [-1., -1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''    inputs list:\n",
    "    - images: [batch, H, W, C]\n",
    "    - image_meta: [batch, (meta data)] Image details. See compose_image_meta()\n",
    "    - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)\n",
    "    - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.\n",
    "    - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs\n",
    "    - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]\n",
    "    - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width\n",
    "                are those of the image unless use_mini_mask is True, in which\n",
    "                case they are defined in MINI_MASK_SHAPE.\n",
    "'''\n",
    "-1*np.ones([5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d38345",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.class_from_source_map\n",
    "dataset_train.image_from_source_map\n",
    "dataset_train.source_class_ids\n",
    "dataset_train.num_classes\n",
    "dataset_train.class_ids\n",
    "dataset_train.class_names\n",
    "dataset_train.num_images\n",
    "dataset_train._image_ids\n",
    "dataset_train.sources\n",
    "augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8baa7b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Create some tensors\n",
    "\n",
    "# # Element-wise addition using tf.add_n\n",
    "\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     tensor1 = tf.constant([1, 2, 3])\n",
    "#     tensor2 = tf.constant([4, 5, 6])\n",
    "#     tensor3 = tf.constant([7, 8, 9])\n",
    "#     result = tf.add_n([tensor1, tensor2, tensor3])\n",
    "#     print(sess.run(result))\n",
    "\n",
    "[1, 2, 3][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e17a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): flatten\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1023\n",
      "The caller function is '_functional_construction_call' in module 'keras.engine.base_layer' (current in base_layer.py 2358)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug keras_tensor.py 243\n",
      "The caller function is 'keras_tensor_to_placeholder' in module 'keras.engine.keras_tensor' (currently in keras_tensor.py 248)\n",
      "keras_tensor.py self: KerasTensor(type_spec=TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\")\n",
      "component_to_placeholder: <function KerasTensor._to_placeholder.<locals>.component_to_placeholder at 0x0000022AC5C05D80>\n",
      "self.type_spec: TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32, name='flatten_input')\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (current in keras.engine.keras_tensor 238)\n",
      "The caller function is 'placeholder' in module 'tensorflow.python.ops.array_ops' (current in gen_array_ops.py 6902)\n",
      "name: None\n",
      "dtype: 1\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug base_layer.py 2441\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '_infer_output_signature' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 2462\n",
      "----------------------------debug base_layer.py 2471\n",
      "----------------------------debug functional.py 1102\n",
      "inputs: [<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>]\n",
      "The caller function is '_init_graph_network' in module 'keras.engine.functional' (current in functional.py 1108)\n",
      "----------------------------debug functional.py 1159\n",
      "len nodes_by_depth: 2\n",
      "layers_with_complete_input: ['flatten']\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_2\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<KerasTensor: shape=(None, 270000) dtype=float32 (created by layer 'flatten')>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1023\n",
      "The caller function is '_functional_construction_call' in module 'keras.engine.base_layer' (current in base_layer.py 2358)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug keras_tensor.py 243\n",
      "The caller function is 'keras_tensor_to_placeholder' in module 'keras.engine.keras_tensor' (currently in keras_tensor.py 248)\n",
      "keras_tensor.py self: KerasTensor(type_spec=TensorSpec(shape=(None, 270000), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "component_to_placeholder: <function KerasTensor._to_placeholder.<locals>.component_to_placeholder at 0x0000022AC5C05D80>\n",
      "self.type_spec: TensorSpec(shape=(None, 270000), dtype=tf.float32, name=None)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (current in keras.engine.keras_tensor 238)\n",
      "The caller function is 'placeholder' in module 'tensorflow.python.ops.array_ops' (current in gen_array_ops.py 6902)\n",
      "name: None\n",
      "dtype: 1\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug base_layer.py 2441\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '_infer_output_signature' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 2462\n",
      "----------------------------debug base_layer.py 2471\n",
      "----------------------------debug functional.py 1102\n",
      "inputs: [<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>]\n",
      "The caller function is '_init_graph_network' in module 'keras.engine.functional' (current in functional.py 1108)\n",
      "----------------------------debug functional.py 1159\n",
      "len nodes_by_depth: 3\n",
      "layers_with_complete_input: ['flatten', 'dense_2']\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): leaky_re_lu\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'dense_2')>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1023\n",
      "The caller function is '_functional_construction_call' in module 'keras.engine.base_layer' (current in base_layer.py 2358)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug keras_tensor.py 243\n",
      "The caller function is 'keras_tensor_to_placeholder' in module 'keras.engine.keras_tensor' (currently in keras_tensor.py 248)\n",
      "keras_tensor.py self: KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name=None), name='dense_2/Relu:0', description=\"created by layer 'dense_2'\")\n",
      "component_to_placeholder: <function KerasTensor._to_placeholder.<locals>.component_to_placeholder at 0x0000022A8A0F3AC0>\n",
      "self.type_spec: TensorSpec(shape=(None, 300), dtype=tf.float32, name=None)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (current in keras.engine.keras_tensor 238)\n",
      "The caller function is 'placeholder' in module 'tensorflow.python.ops.array_ops' (current in gen_array_ops.py 6902)\n",
      "name: None\n",
      "dtype: 1\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug base_layer.py 2441\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '_infer_output_signature' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 2462\n",
      "----------------------------debug base_layer.py 2471\n",
      "----------------------------debug functional.py 1102\n",
      "inputs: [<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>]\n",
      "The caller function is '_init_graph_network' in module 'keras.engine.functional' (current in functional.py 1108)\n",
      "----------------------------debug functional.py 1159\n",
      "len nodes_by_depth: 4\n",
      "layers_with_complete_input: ['flatten', 'dense_2', 'leaky_re_lu']\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_3\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'leaky_re_lu')>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1023\n",
      "The caller function is '_functional_construction_call' in module 'keras.engine.base_layer' (current in base_layer.py 2358)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug keras_tensor.py 243\n",
      "The caller function is 'keras_tensor_to_placeholder' in module 'keras.engine.keras_tensor' (currently in keras_tensor.py 248)\n",
      "keras_tensor.py self: KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name=None), name='leaky_re_lu/LeakyRelu:0', description=\"created by layer 'leaky_re_lu'\")\n",
      "component_to_placeholder: <function KerasTensor._to_placeholder.<locals>.component_to_placeholder at 0x0000022A8A0F39A0>\n",
      "self.type_spec: TensorSpec(shape=(None, 300), dtype=tf.float32, name=None)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (current in keras.engine.keras_tensor 238)\n",
      "The caller function is 'placeholder' in module 'tensorflow.python.ops.array_ops' (current in gen_array_ops.py 6902)\n",
      "name: None\n",
      "dtype: 1\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug base_layer.py 2441\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '_infer_output_signature' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 2462\n",
      "----------------------------debug base_layer.py 2471\n",
      "----------------------------debug functional.py 1102\n",
      "inputs: [<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>]\n",
      "The caller function is '_init_graph_network' in module 'keras.engine.functional' (current in functional.py 1108)\n",
      "----------------------------debug functional.py 1159\n",
      "len nodes_by_depth: 5\n",
      "layers_with_complete_input: ['flatten', 'dense_2', 'leaky_re_lu', 'dense_3']\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_4\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<KerasTensor: shape=(None, 600) dtype=float32 (created by layer 'dense_3')>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1023\n",
      "The caller function is '_functional_construction_call' in module 'keras.engine.base_layer' (current in base_layer.py 2358)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug keras_tensor.py 243\n",
      "The caller function is 'keras_tensor_to_placeholder' in module 'keras.engine.keras_tensor' (currently in keras_tensor.py 248)\n",
      "keras_tensor.py self: KerasTensor(type_spec=TensorSpec(shape=(None, 600), dtype=tf.float32, name=None), name='dense_3/Relu:0', description=\"created by layer 'dense_3'\")\n",
      "component_to_placeholder: <function KerasTensor._to_placeholder.<locals>.component_to_placeholder at 0x0000022A8A0F3AC0>\n",
      "self.type_spec: TensorSpec(shape=(None, 600), dtype=tf.float32, name=None)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (current in keras.engine.keras_tensor 238)\n",
      "The caller function is 'placeholder' in module 'tensorflow.python.ops.array_ops' (current in gen_array_ops.py 6902)\n",
      "name: None\n",
      "dtype: 1\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug base_layer.py 2441\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '_infer_output_signature' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 2462\n",
      "----------------------------debug base_layer.py 2471\n",
      "----------------------------debug functional.py 1102\n",
      "inputs: [<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>]\n",
      "The caller function is '_init_graph_network' in module 'keras.engine.functional' (current in functional.py 1108)\n",
      "----------------------------debug functional.py 1159\n",
      "len nodes_by_depth: 6\n",
      "layers_with_complete_input: ['flatten', 'dense_2', 'leaky_re_lu', 'dense_3', 'dense_4']\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_5\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<KerasTensor: shape=(None, 600) dtype=float32 (created by layer 'dense_4')>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1023\n",
      "The caller function is '_functional_construction_call' in module 'keras.engine.base_layer' (current in base_layer.py 2358)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug keras_tensor.py 243\n",
      "The caller function is 'keras_tensor_to_placeholder' in module 'keras.engine.keras_tensor' (currently in keras_tensor.py 248)\n",
      "keras_tensor.py self: KerasTensor(type_spec=TensorSpec(shape=(None, 600), dtype=tf.float32, name=None), name='dense_4/Relu:0', description=\"created by layer 'dense_4'\")\n",
      "component_to_placeholder: <function KerasTensor._to_placeholder.<locals>.component_to_placeholder at 0x0000022ACF557520>\n",
      "self.type_spec: TensorSpec(shape=(None, 600), dtype=tf.float32, name=None)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (current in keras.engine.keras_tensor 238)\n",
      "The caller function is 'placeholder' in module 'tensorflow.python.ops.array_ops' (current in gen_array_ops.py 6902)\n",
      "name: None\n",
      "dtype: 1\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug base_layer.py 2441\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '_infer_output_signature' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 2462\n",
      "----------------------------debug base_layer.py 2471\n",
      "----------------------------debug functional.py 1102\n",
      "inputs: [<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>]\n",
      "The caller function is '_init_graph_network' in module 'keras.engine.functional' (current in functional.py 1108)\n",
      "----------------------------debug functional.py 1159\n",
      "len nodes_by_depth: 7\n",
      "layers_with_complete_input: ['flatten', 'dense_2', 'leaky_re_lu', 'dense_3', 'dense_4', 'dense_5']\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_6\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'dense_5')>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1023\n",
      "The caller function is '_functional_construction_call' in module 'keras.engine.base_layer' (current in base_layer.py 2358)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug keras_tensor.py 243\n",
      "The caller function is 'keras_tensor_to_placeholder' in module 'keras.engine.keras_tensor' (currently in keras_tensor.py 248)\n",
      "keras_tensor.py self: KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name=None), name='dense_5/Relu:0', description=\"created by layer 'dense_5'\")\n",
      "component_to_placeholder: <function KerasTensor._to_placeholder.<locals>.component_to_placeholder at 0x0000022A8A0F3AC0>\n",
      "self.type_spec: TensorSpec(shape=(None, 300), dtype=tf.float32, name=None)\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (current in keras.engine.keras_tensor 238)\n",
      "The caller function is 'placeholder' in module 'tensorflow.python.ops.array_ops' (current in gen_array_ops.py 6902)\n",
      "name: None\n",
      "dtype: 1\n",
      "The caller function is '<listcomp>' in module 'tensorflow.python.util.nest' (currently in keras_tensor.py 670)\n",
      "----------------------------debug base_layer.py 2441\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '_infer_output_signature' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 2462\n",
      "----------------------------debug base_layer.py 2471\n",
      "----------------------------debug functional.py 1102\n",
      "inputs: [<KerasTensor: shape=(None, 300, 300, 3) dtype=float32 (created by layer 'flatten_input')>]\n",
      "The caller function is '_init_graph_network' in module 'keras.engine.functional' (current in functional.py 1108)\n",
      "----------------------------debug functional.py 1159\n",
      "len nodes_by_depth: 8\n",
      "layers_with_complete_input: ['flatten', 'dense_2', 'leaky_re_lu', 'dense_3', 'dense_4', 'dense_5', 'dense_6']\n",
      "Model: \"sequential\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 270000)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               81000300  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 600)               180600    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 600)               360600    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 300)               180300    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,724,810\n",
      "Trainable params: 81,724,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "----------------------------debug training.py 1508\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils'\n",
      "----------------------------debug function.py 2654\n",
      "The caller function is '_maybe_define_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug func_graph.py 1187\n",
      "The caller function is '_create_graph_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug function.py 2654\n",
      "The caller function is '_maybe_define_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug func_graph.py 1187\n",
      "The caller function is '_create_graph_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug function.py 2654\n",
      "The caller function is '_maybe_define_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug func_graph.py 1187\n",
      "The caller function is '_create_graph_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "Epoch 1/30\n",
      "----------------------------debug def_function.py 755\n",
      "The caller function is '_call' in module 'tensorflow.python.eager.def_function'\n",
      "----------------------------debug function.py 2520\n",
      "The caller function is '_initialize' in module 'tensorflow.python.eager.def_function'\n",
      "----------------------------debug function.py 2654\n",
      "The caller function is '_maybe_define_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug func_graph.py 1187\n",
      "The caller function is '_create_graph_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug def_function.py 672\n",
      "The caller function is 'func_graph_from_py_func' in module 'tensorflow.python.framework.func_graph'\n",
      "----------------------------debug func_graph.py 1267\n",
      "The caller function is 'wrapped_fn' in module 'tensorflow.python.eager.def_function'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'autograph_handler' in module 'tensorflow.python.framework.func_graph'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'tf__train_function' in module '__autograph_generated_file69487loy'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 1189\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "data: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 1167\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 991\n",
      "The caller function is 'run_step' in module 'keras.engine.training'\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): sequential\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {'training': True}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): flatten\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/flatten/Reshape:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_2\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/flatten/Reshape:0' shape=(None, 270000) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/flatten/Reshape:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_2/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): leaky_re_lu\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_2/Relu:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_2/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_3\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/leaky_re_lu/LeakyRelu:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_3/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_4\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_3/Relu:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_3/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_4/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_5\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_4/Relu:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_4/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_5/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_6\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_5/Relu:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_5/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "values: Tensor(\"Mul:0\", shape=(), dtype=float32)\n",
      "x: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "data: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "self.trainable_variables: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "----------------------------debug optimizer_v2.py 639\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "tape: <tensorflow.python.eager.backprop.GradientTape object at 0x0000022AC5C00F40>\n",
      "loss: Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "----------------------------debug optimizer_v2.py 511\n",
      "loss type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss dir: ['OVERLOADABLE_OPERATORS', '_USE_EQUALITY', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__bool__', '__class__', '__copy__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__iter__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__tf_tracing_type__', '__truediv__', '__weakref__', '__xor__', '_as_node_def_input', '_as_tf_output', '_c_api_shape', '_consumers', '_create_with_tf_output', '_disallow_bool_casting', '_disallow_in_graph_mode', '_disallow_iteration', '_disallow_when_autograph_disabled', '_disallow_when_autograph_enabled', '_disallow_when_autograph_unavailable', '_dtype', '_id', '_matmul', '_name', '_numpy_style_getitem', '_op', '_override_operator', '_rank', '_shape', '_shape_as_list', '_shape_tuple', '_shape_val', '_tf_api_names', '_tf_api_names_v1', '_tf_output', '_value_index', '_with_index_add', '_with_index_max', '_with_index_min', '_with_index_update', 'consumers', 'device', 'dtype', 'eval', 'experimental_ref', 'get_shape', 'graph', 'name', 'op', 'ref', 'set_shape', 'shape', 'value_index']\n",
      "loss consumers: [<tf.Operation 'Mul' type=Mul>, <tf.Operation 'SGD/gradients/mul' type=Mul>]\n",
      "loss device: \n",
      "loss experimental_ref: <Reference wrapping <tf.Tensor 'sparse_categorical_crossentropy/weighted_loss/value:0' shape=() dtype=float32>>\n",
      "loss get_shape: ()\n",
      "loss name: sparse_categorical_crossentropy/weighted_loss/value:0\n",
      "The caller function is '_compute_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "grads: [<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/MatMul/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/MatMul/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/MatMul/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/MatMul/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd/BiasAddGrad:0' shape=(10,) dtype=float32>]\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "grad_loss: None\n",
      "----------------------------debug optimizer_v2.py 579\n",
      "The caller function is 'train_step' in module 'keras.engine.training'\n",
      "----------------------------debug optimizer_v2.py 689\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'apply_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2' (current in utils.py 68)\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'all_reduce_sum_gradients' in module 'keras.optimizers.optimizer_v2.utils' (current in utils.py 68)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug compile_utils.py 604\n",
      "The caller function is 'compute_metrics' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "y_true: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug compile_utils.py 484\n",
      "The caller function is 'update_state' in module 'keras.engine.compile_utils' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "y_true: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug compile_utils.py 675\n",
      "The caller function is '<listcomp>' in module 'keras.engine.compile_utils' (current in keras.engine.keras_tensor 238)\n",
      "y_t: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is 'update_state' in module 'keras.metrics.base_metric'\n",
      "values: Tensor(\"Squeeze_1:0\", shape=(None,), dtype=float32)\n",
      "----------------------------debug training.py 1121\n",
      "The caller function is 'train_step' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 991\n",
      "The caller function is 'step_function' in module 'keras.engine.training'\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): sequential\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {'training': True}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): flatten\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/flatten/Reshape_1:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_2\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/flatten/Reshape_1:0' shape=(None, 270000) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/flatten/Reshape_1:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_2/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): leaky_re_lu\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_2/Relu_1:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_2/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_3\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/leaky_re_lu/LeakyRelu_1:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_3/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_4\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_3/Relu_1:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_3/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_4/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_5\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_4/Relu_1:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_4/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: Tensor(\"sequential/dense_5/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_6\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_5/Relu_1:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_5/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "values: Tensor(\"Mul_1:0\", shape=(), dtype=float32)\n",
      "x: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "data: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "self.trainable_variables: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "----------------------------debug optimizer_v2.py 639\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "tape: <tensorflow.python.eager.backprop.GradientTape object at 0x0000022AC5CC0460>\n",
      "loss: Tensor(\"sparse_categorical_crossentropy_1/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "----------------------------debug optimizer_v2.py 511\n",
      "loss type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss dir: ['OVERLOADABLE_OPERATORS', '_USE_EQUALITY', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__bool__', '__class__', '__copy__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__iter__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__tf_tracing_type__', '__truediv__', '__weakref__', '__xor__', '_as_node_def_input', '_as_tf_output', '_c_api_shape', '_consumers', '_create_with_tf_output', '_disallow_bool_casting', '_disallow_in_graph_mode', '_disallow_iteration', '_disallow_when_autograph_disabled', '_disallow_when_autograph_enabled', '_disallow_when_autograph_unavailable', '_dtype', '_id', '_matmul', '_name', '_numpy_style_getitem', '_op', '_override_operator', '_rank', '_shape', '_shape_as_list', '_shape_tuple', '_shape_val', '_tf_api_names', '_tf_api_names_v1', '_tf_output', '_value_index', '_with_index_add', '_with_index_max', '_with_index_min', '_with_index_update', 'consumers', 'device', 'dtype', 'eval', 'experimental_ref', 'get_shape', 'graph', 'name', 'op', 'ref', 'set_shape', 'shape', 'value_index']\n",
      "loss consumers: [<tf.Operation 'Mul_1' type=Mul>, <tf.Operation 'SGD/gradients_1/mul' type=Mul>]\n",
      "loss device: \n",
      "loss experimental_ref: <Reference wrapping <tf.Tensor 'sparse_categorical_crossentropy_1/weighted_loss/value:0' shape=() dtype=float32>>\n",
      "loss get_shape: ()\n",
      "loss name: sparse_categorical_crossentropy_1/weighted_loss/value:0\n",
      "The caller function is '_compute_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "grads: [<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul_1/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/MatMul_1/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/MatMul_1/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/MatMul_1/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/MatMul_1/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd_1/BiasAddGrad:0' shape=(10,) dtype=float32>]\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "grad_loss: None\n",
      "----------------------------debug optimizer_v2.py 579\n",
      "The caller function is 'train_step' in module 'keras.engine.training'\n",
      "----------------------------debug optimizer_v2.py 689\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul_1/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul_1/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul_1/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul_1/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul_1/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd_1/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'apply_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2' (current in utils.py 68)\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul_1/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul_1/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul_1/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul_1/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul_1/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd_1/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'all_reduce_sum_gradients' in module 'keras.optimizers.optimizer_v2.utils' (current in utils.py 68)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug compile_utils.py 604\n",
      "The caller function is 'compute_metrics' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "y_true: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is 'update_state' in module 'keras.metrics.base_metric'\n",
      "values: Tensor(\"Squeeze_3:0\", shape=(None,), dtype=float32)\n",
      "----------------------------debug training.py 1121\n",
      "The caller function is 'train_step' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug function.py 2654\n",
      "The caller function is '_maybe_define_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug func_graph.py 1187\n",
      "The caller function is '_create_graph_function' in module 'tensorflow.python.eager.function'\n",
      "----------------------------debug def_function.py 672\n",
      "The caller function is 'func_graph_from_py_func' in module 'tensorflow.python.framework.func_graph'\n",
      "----------------------------debug func_graph.py 1267\n",
      "The caller function is 'wrapped_fn' in module 'tensorflow.python.eager.def_function'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'autograph_handler' in module 'tensorflow.python.framework.func_graph'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'tf__train_function' in module '__autograph_generated_file69487loy'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 1189\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "data: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 1167\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 991\n",
      "The caller function is 'run_step' in module 'keras.engine.training'\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): sequential\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {'training': True}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): flatten\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/flatten/Reshape:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_2\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/flatten/Reshape:0' shape=(None, 270000) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/flatten/Reshape:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_2/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): leaky_re_lu\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_2/Relu:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_2/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_3\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/leaky_re_lu/LeakyRelu:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_3/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_4\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_3/Relu:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_3/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_4/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_5\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_4/Relu:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_4/Relu:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_5/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_6\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_5/Relu:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_5/Relu:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "values: Tensor(\"Mul:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "data: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "self.trainable_variables: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "----------------------------debug optimizer_v2.py 639\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "tape: <tensorflow.python.eager.backprop.GradientTape object at 0x0000022BBF74E800>\n",
      "loss: Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "----------------------------debug optimizer_v2.py 511\n",
      "loss type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss dir: ['OVERLOADABLE_OPERATORS', '_USE_EQUALITY', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__bool__', '__class__', '__copy__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__iter__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__tf_tracing_type__', '__truediv__', '__weakref__', '__xor__', '_as_node_def_input', '_as_tf_output', '_c_api_shape', '_consumers', '_create_with_tf_output', '_disallow_bool_casting', '_disallow_in_graph_mode', '_disallow_iteration', '_disallow_when_autograph_disabled', '_disallow_when_autograph_enabled', '_disallow_when_autograph_unavailable', '_dtype', '_id', '_matmul', '_name', '_numpy_style_getitem', '_op', '_override_operator', '_rank', '_shape', '_shape_as_list', '_shape_tuple', '_shape_val', '_tf_api_names', '_tf_api_names_v1', '_tf_output', '_value_index', '_with_index_add', '_with_index_max', '_with_index_min', '_with_index_update', 'consumers', 'device', 'dtype', 'eval', 'experimental_ref', 'get_shape', 'graph', 'name', 'op', 'ref', 'set_shape', 'shape', 'value_index']\n",
      "loss consumers: [<tf.Operation 'Mul' type=Mul>, <tf.Operation 'SGD/gradients/mul' type=Mul>]\n",
      "loss device: \n",
      "loss experimental_ref: <Reference wrapping <tf.Tensor 'sparse_categorical_crossentropy/weighted_loss/value:0' shape=() dtype=float32>>\n",
      "loss get_shape: ()\n",
      "loss name: sparse_categorical_crossentropy/weighted_loss/value:0\n",
      "The caller function is '_compute_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "grads: [<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/MatMul/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/MatMul/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/MatMul/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/MatMul/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd/BiasAddGrad:0' shape=(10,) dtype=float32>]\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "grad_loss: None\n",
      "----------------------------debug optimizer_v2.py 579\n",
      "The caller function is 'train_step' in module 'keras.engine.training'\n",
      "----------------------------debug optimizer_v2.py 689\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'apply_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2' (current in utils.py 68)\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'all_reduce_sum_gradients' in module 'keras.optimizers.optimizer_v2.utils' (current in utils.py 68)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug compile_utils.py 604\n",
      "The caller function is 'compute_metrics' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "y_true: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is 'update_state' in module 'keras.metrics.base_metric'\n",
      "values: Tensor(\"Squeeze_1:0\", shape=(None,), dtype=float32)\n",
      "----------------------------debug training.py 1121\n",
      "The caller function is 'train_step' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug training.py 991\n",
      "The caller function is 'step_function' in module 'keras.engine.training'\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): sequential\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {'training': True}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): flatten\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/flatten/Reshape_1:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_2\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/flatten/Reshape_1:0' shape=(None, 270000) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/flatten/Reshape_1:0\", shape=(None, 270000), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_2/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): leaky_re_lu\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_2/Relu_1:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_2/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_3\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/leaky_re_lu/LeakyRelu_1:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/leaky_re_lu/LeakyRelu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_3/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_4\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_3/Relu_1:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_3/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_4/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_5\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_4/Relu_1:0' shape=(None, 600) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_4/Relu_1:0\", shape=(None, 600), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_5/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug base_layer.py 983\n",
      "str(self.name): dense_6\n",
      "The caller function is 'error_handler' in module 'keras.utils.traceback_utils' (current in base_layer.py 989)\n",
      "args: (<tf.Tensor 'sequential/dense_5/Relu_1:0' shape=(None, 300) dtype=float32>,)\n",
      "kwargs: {}\n",
      "----------------------------debug base_layer.py 1009\n",
      "----------------------------debug base_layer.py 1011\n",
      "----------------------------debug base_layer.py 1013\n",
      "----------------------------debug base_layer.py 1048\n",
      "----------------------------debug base_layer.py 1112\n",
      "inputs: Tensor(\"sequential/dense_5/Relu_1:0\", shape=(None, 300), dtype=float32)\n",
      "----------------------------debug traceback_utils.py 101\n",
      "The caller function is '__call__' in module 'keras.engine.base_layer' (current in base_layer.py 989)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "outputs: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is '_call_unconverted' in module 'tensorflow.python.autograph.impl.api'\n",
      "values: Tensor(\"Mul_1:0\", shape=(), dtype=float32)\n",
      "x: Tensor(\"IteratorGetNext:0\", shape=(None, 300, 300, 3), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "data: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 300, 300, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "self.trainable_variables: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "----------------------------debug optimizer_v2.py 639\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "tape: <tensorflow.python.eager.backprop.GradientTape object at 0x0000022BBF723340>\n",
      "loss: Tensor(\"sparse_categorical_crossentropy_1/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "----------------------------debug optimizer_v2.py 511\n",
      "loss type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "loss dir: ['OVERLOADABLE_OPERATORS', '_USE_EQUALITY', '__abs__', '__add__', '__and__', '__annotations__', '__array__', '__array_priority__', '__bool__', '__class__', '__copy__', '__delattr__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__floordiv__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__invert__', '__iter__', '__le__', '__len__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rand__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rmatmul__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__tf_tracing_type__', '__truediv__', '__weakref__', '__xor__', '_as_node_def_input', '_as_tf_output', '_c_api_shape', '_consumers', '_create_with_tf_output', '_disallow_bool_casting', '_disallow_in_graph_mode', '_disallow_iteration', '_disallow_when_autograph_disabled', '_disallow_when_autograph_enabled', '_disallow_when_autograph_unavailable', '_dtype', '_id', '_matmul', '_name', '_numpy_style_getitem', '_op', '_override_operator', '_rank', '_shape', '_shape_as_list', '_shape_tuple', '_shape_val', '_tf_api_names', '_tf_api_names_v1', '_tf_output', '_value_index', '_with_index_add', '_with_index_max', '_with_index_min', '_with_index_update', 'consumers', 'device', 'dtype', 'eval', 'experimental_ref', 'get_shape', 'graph', 'name', 'op', 'ref', 'set_shape', 'shape', 'value_index']\n",
      "loss consumers: [<tf.Operation 'Mul_1' type=Mul>, <tf.Operation 'SGD/gradients_1/mul' type=Mul>]\n",
      "loss device: \n",
      "loss experimental_ref: <Reference wrapping <tf.Tensor 'sparse_categorical_crossentropy_1/weighted_loss/value:0' shape=() dtype=float32>>\n",
      "loss get_shape: ()\n",
      "loss name: sparse_categorical_crossentropy_1/weighted_loss/value:0\n",
      "The caller function is '_compute_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "grads: [<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul_1/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/MatMul_1/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/MatMul_1/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/MatMul_1/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/MatMul_1/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd_1/BiasAddGrad:0' shape=(10,) dtype=float32>]\n",
      "var_list: [<tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>]\n",
      "grad_loss: None\n",
      "----------------------------debug optimizer_v2.py 579\n",
      "The caller function is 'train_step' in module 'keras.engine.training'\n",
      "----------------------------debug optimizer_v2.py 689\n",
      "The caller function is 'minimize' in module 'keras.optimizers.optimizer_v2.optimizer_v2'\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul_1/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul_1/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul_1/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul_1/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul_1/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd_1/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'apply_gradients' in module 'keras.optimizers.optimizer_v2.optimizer_v2' (current in utils.py 68)\n",
      "----------------------------debug utils.py 62\n",
      "grads_and_vars: [(<tf.Tensor 'gradient_tape/sequential/dense_2/MatMul_1/MatMul:0' shape=(270000, 300) dtype=float32>, <tf.Variable 'dense_2/kernel:0' shape=(270000, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_2/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/MatMul_1/MatMul_1:0' shape=(300, 600) dtype=float32>, <tf.Variable 'dense_3/kernel:0' shape=(300, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_3/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_3/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/MatMul_1/MatMul_1:0' shape=(600, 600) dtype=float32>, <tf.Variable 'dense_4/kernel:0' shape=(600, 600) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_4/BiasAdd_1/BiasAddGrad:0' shape=(600,) dtype=float32>, <tf.Variable 'dense_4/bias:0' shape=(600,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/MatMul_1/MatMul_1:0' shape=(600, 300) dtype=float32>, <tf.Variable 'dense_5/kernel:0' shape=(600, 300) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_5/BiasAdd_1/BiasAddGrad:0' shape=(300,) dtype=float32>, <tf.Variable 'dense_5/bias:0' shape=(300,) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/MatMul_1/MatMul_1:0' shape=(300, 10) dtype=float32>, <tf.Variable 'dense_6/kernel:0' shape=(300, 10) dtype=float32>), (<tf.Tensor 'gradient_tape/sequential/dense_6/BiasAdd_1/BiasAddGrad:0' shape=(10,) dtype=float32>, <tf.Variable 'dense_6/bias:0' shape=(10,) dtype=float32>)]\n",
      "The caller function is 'all_reduce_sum_gradients' in module 'keras.optimizers.optimizer_v2.utils' (current in utils.py 68)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------debug compile_utils.py 604\n",
      "The caller function is 'compute_metrics' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "y_true: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug base_metric.py 503\n",
      "The caller function is 'update_state' in module 'keras.metrics.base_metric'\n",
      "values: Tensor(\"Squeeze_3:0\", shape=(None,), dtype=float32)\n",
      "----------------------------debug training.py 1121\n",
      "The caller function is 'train_step' in module 'keras.engine.training' (current in keras.engine.keras_tensor 238)\n",
      "y_pred: Tensor(\"sequential/dense_6/Softmax_1:0\", shape=(None, 10), dtype=float32)\n",
      "y: Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=float32)\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 321\n",
      "The caller function is 'wrapper' in module 'tensorflow.python.autograph.impl.api'\n",
      "----------------------------debug api.py 451\n",
      "The caller function is 'converted_call' in module 'tensorflow.python.autograph.impl.api'\n",
      "33/75 [============>.................] - ETA: 12s - loss: 8.4518 - accuracy: 0.1394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Roses', 'Magnolias', 'Lilies', 'Sunflowers', 'Orchids', \n",
    "               'Marigold', 'Hibiscus', 'Firebush', 'Pentas', 'Bougainvillea']\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "\n",
    "# Loading Training Data\n",
    "X_train_full = np.load('data_train.npy').T\n",
    "t_train_full = np.load('labels_train.npy')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# compression with the images from input to the first h layer\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[300,300, 3]),\n",
    "    keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(alpha=(0.2)),\n",
    "    keras.layers.Dense(600, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(600, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "# opt = keras.optimizers.Nadam(lr=0.01, beta_2=0.08, epsilon=1e-08, clipvalue=5.0)\n",
    "opt = keras.optimizers.SGD(lr=0.075, momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd', # stochastic gradient descent\n",
    "              metrics=['accuracy'])\n",
    "X_train_full = X_train_full.reshape((1658,300,300,3))\n",
    "\n",
    "X_valid, X_train = X_train_full[:165] / 255.0, X_train_full[165:] / 255.0\n",
    "t_valid, t_train = t_train_full[:165], t_train_full[165:]\n",
    "history = model.fit(X_train, t_train, epochs=30, batch_size=20,\n",
    "                   validation_data=(X_valid, t_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "206b1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(dataset, config, shuffle=True, augment=False, augmentation=None,\n",
    "                   random_rois=0, batch_size=1, detection_targets=False,\n",
    "                   no_augmentation_sources=None):\n",
    "    \"\"\"A generator that returns images and corresponding target class ids,\n",
    "    bounding box deltas, and masks.\n",
    "\n",
    "    dataset: The Dataset object to pick data from\n",
    "    config: The model config object\n",
    "    shuffle: If True, shuffles the samples before every epoch\n",
    "    augment: (deprecated. Use augmentation instead). If true, apply random\n",
    "        image augmentation. Currently, only horizontal flipping is offered.\n",
    "    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "    random_rois: If > 0 then generate proposals to be used to train the\n",
    "                 network classifier and mask heads. Useful if training\n",
    "                 the Mask RCNN part without the RPN.\n",
    "    batch_size: How many images to return in each call\n",
    "    detection_targets: If True, generate detection targets (class IDs, bbox\n",
    "        deltas, and masks). Typically for debugging or visualizations because\n",
    "        in trainig detection targets are generated by DetectionTargetLayer.\n",
    "    no_augmentation_sources: Optional. List of sources to exclude for\n",
    "        augmentation. A source is string that identifies a dataset and is\n",
    "        defined in the Dataset class.\n",
    "\n",
    "    Returns a Python generator. Upon calling next() on it, the\n",
    "    generator returns two lists, inputs and outputs. The contents\n",
    "    of the lists differs depending on the received arguments:\n",
    "    inputs list:\n",
    "    - images: [batch, H, W, C]\n",
    "    - image_meta: [batch, (meta data)] Image details. See compose_image_meta()\n",
    "    - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)\n",
    "    - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.\n",
    "    - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs\n",
    "    - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]\n",
    "    - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width\n",
    "                are those of the image unless use_mini_mask is True, in which\n",
    "                case they are defined in MINI_MASK_SHAPE.\n",
    "\n",
    "    outputs list: Usually empty in regular training. But if detection_targets\n",
    "        is True then the outputs list contains target class_ids, bbox deltas,\n",
    "        and masks.\n",
    "    \"\"\"\n",
    "    b = 0  # batch item index\n",
    "    image_index = -1\n",
    "    image_ids = np.copy(dataset.image_ids)\n",
    "    error_count = 0\n",
    "    no_augmentation_sources = no_augmentation_sources or []\n",
    "\n",
    "    # Anchors\n",
    "    # [anchor_count, (y1, x1, y2, x2)]\n",
    "    backbone_shapes = compute_backbone_shapes(config, config.IMAGE_SHAPE)\n",
    "    anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,\n",
    "                                             config.RPN_ANCHOR_RATIOS,\n",
    "                                             backbone_shapes,\n",
    "                                             config.BACKBONE_STRIDES,\n",
    "                                             config.RPN_ANCHOR_STRIDE)\n",
    "\n",
    "    # Keras requires a generator to run indefinitely.\n",
    "    while True:\n",
    "        try:\n",
    "            # Increment index to pick next image. Shuffle if at the start of an epoch.\n",
    "            image_index = (image_index + 1) % len(image_ids)\n",
    "            if shuffle and image_index == 0:\n",
    "                np.random.shuffle(image_ids)\n",
    "\n",
    "            # Get GT bounding boxes and masks for image.\n",
    "            image_id = image_ids[image_index]\n",
    "\n",
    "            # If the image source is not to be augmented pass None as augmentation\n",
    "            if dataset.image_info[image_id]['source'] in no_augmentation_sources:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                              augmentation=None,\n",
    "                              use_mini_mask=config.USE_MINI_MASK)\n",
    "            else:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                    load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                                augmentation=augmentation,\n",
    "                                use_mini_mask=config.USE_MINI_MASK)\n",
    "\n",
    "            # Skip images that have no instances. This can happen in cases\n",
    "            # where we train on a subset of classes and the image doesn't\n",
    "            # have any of the classes we care about.\n",
    "            if not np.any(gt_class_ids > 0):\n",
    "                continue\n",
    "\n",
    "            # RPN Targets\n",
    "            rpn_match, rpn_bbox = build_rpn_targets(image.shape, anchors,\n",
    "                                                    gt_class_ids, gt_boxes, config)\n",
    "\n",
    "            # Mask R-CNN Targets\n",
    "            if random_rois:\n",
    "                rpn_rois = generate_random_rois(\n",
    "                    image.shape, random_rois, gt_class_ids, gt_boxes)\n",
    "                if detection_targets:\n",
    "                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask =\\\n",
    "                        build_detection_targets(\n",
    "                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, config)\n",
    "\n",
    "            # Init batch arrays\n",
    "            if b == 0:\n",
    "                batch_image_meta = np.zeros(\n",
    "                    (batch_size,) + image_meta.shape, dtype=image_meta.dtype)\n",
    "                batch_rpn_match = np.zeros(\n",
    "                    [batch_size, anchors.shape[0], 1], dtype=rpn_match.dtype)\n",
    "                batch_rpn_bbox = np.zeros(\n",
    "                    [batch_size, config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4], dtype=rpn_bbox.dtype)\n",
    "                batch_images = np.zeros(\n",
    "                    (batch_size,) + image.shape, dtype=np.float32)\n",
    "                batch_gt_class_ids = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES), dtype=np.int32)\n",
    "                batch_gt_boxes = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES, 4), dtype=np.int32)\n",
    "                batch_gt_masks = np.zeros(\n",
    "                    (batch_size, gt_masks.shape[0], gt_masks.shape[1],\n",
    "                     config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)\n",
    "                if random_rois:\n",
    "                    batch_rpn_rois = np.zeros(\n",
    "                        (batch_size, rpn_rois.shape[0], 4), dtype=rpn_rois.dtype)\n",
    "                    if detection_targets:\n",
    "                        batch_rois = np.zeros(\n",
    "                            (batch_size,) + rois.shape, dtype=rois.dtype)\n",
    "                        batch_mrcnn_class_ids = np.zeros(\n",
    "                            (batch_size,) + mrcnn_class_ids.shape, dtype=mrcnn_class_ids.dtype)\n",
    "                        batch_mrcnn_bbox = np.zeros(\n",
    "                            (batch_size,) + mrcnn_bbox.shape, dtype=mrcnn_bbox.dtype)\n",
    "                        batch_mrcnn_mask = np.zeros(\n",
    "                            (batch_size,) + mrcnn_mask.shape, dtype=mrcnn_mask.dtype)\n",
    "\n",
    "            # If more instances than fits in the array, sub-sample from them.\n",
    "            if gt_boxes.shape[0] > config.MAX_GT_INSTANCES:\n",
    "                ids = np.random.choice(\n",
    "                    np.arange(gt_boxes.shape[0]), config.MAX_GT_INSTANCES, replace=False)\n",
    "                gt_class_ids = gt_class_ids[ids]\n",
    "                gt_boxes = gt_boxes[ids]\n",
    "                gt_masks = gt_masks[:, :, ids]\n",
    "\n",
    "            # Add to batch\n",
    "            batch_image_meta[b] = image_meta\n",
    "            batch_rpn_match[b] = rpn_match[:, np.newaxis]\n",
    "            batch_rpn_bbox[b] = rpn_bbox\n",
    "            batch_images[b] = mold_image(image.astype(np.float32), config)\n",
    "            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids\n",
    "            batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes\n",
    "            batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks\n",
    "            if random_rois:\n",
    "                batch_rpn_rois[b] = rpn_rois\n",
    "                if detection_targets:\n",
    "                    batch_rois[b] = rois\n",
    "                    batch_mrcnn_class_ids[b] = mrcnn_class_ids\n",
    "                    batch_mrcnn_bbox[b] = mrcnn_bbox\n",
    "                    batch_mrcnn_mask[b] = mrcnn_mask\n",
    "            b += 1\n",
    "\n",
    "            # Batch full?\n",
    "            if b >= batch_size:\n",
    "                inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,\n",
    "                          batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]\n",
    "                outputs = []\n",
    "\n",
    "                if random_rois:\n",
    "                    inputs.extend([batch_rpn_rois])\n",
    "                    if detection_targets:\n",
    "                        inputs.extend([batch_rois])\n",
    "                        # Keras requires that output and targets have the same number of dimensions\n",
    "                        batch_mrcnn_class_ids = np.expand_dims(\n",
    "                            batch_mrcnn_class_ids, -1)\n",
    "                        outputs.extend(\n",
    "                            [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])\n",
    "\n",
    "                yield inputs, outputs\n",
    "\n",
    "                # start a new batch\n",
    "                b = 0\n",
    "        except (GeneratorExit, KeyboardInterrupt):\n",
    "            raise\n",
    "        except:\n",
    "            # Log it and skip the image\n",
    "            logging.exception(\"Error processing image {}\".format(\n",
    "                dataset.image_info[image_id]))\n",
    "            error_count += 1\n",
    "            if error_count > 5:\n",
    "                raise\n",
    "\n",
    "\n",
    "def compute_backbone_shapes(config, image_shape):\n",
    "    \"\"\"Computes the width and height of each stage of the backbone network.\n",
    "\n",
    "    Returns:\n",
    "        [N, (height, width)]. Where N is the number of stages\n",
    "    \"\"\"\n",
    "    if callable(config.BACKBONE):\n",
    "        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n",
    "\n",
    "    # Currently supports ResNet only\n",
    "    assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n",
    "    return np.array(\n",
    "        [[int(math.ceil(image_shape[0] / stride)),\n",
    "            int(math.ceil(image_shape[1] / stride))]\n",
    "            for stride in config.BACKBONE_STRIDES])\n",
    "\n",
    "def load_image_gt(dataset, config, image_id, augment=False, augmentation=None,\n",
    "                  use_mini_mask=False):\n",
    "    \"\"\"Load and return ground truth data for an image (image, mask, bounding boxes).\n",
    "\n",
    "    augment: (deprecated. Use augmentation instead). If true, apply random\n",
    "        image augmentation. Currently, only horizontal flipping is offered.\n",
    "    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "    use_mini_mask: If False, returns full-size masks that are the same height\n",
    "        and width as the original image. These can be big, for example\n",
    "        1024x1024x100 (for 100 instances). Mini masks are smaller, typically,\n",
    "        224x224 and are generated by extracting the bounding box of the\n",
    "        object and resizing it to MINI_MASK_SHAPE.\n",
    "\n",
    "    Returns:\n",
    "    image: [height, width, 3]\n",
    "    shape: the original shape of the image before resizing and cropping.\n",
    "    class_ids: [instance_count] Integer class IDs\n",
    "    bbox: [instance_count, (y1, x1, y2, x2)]\n",
    "    mask: [height, width, instance_count]. The height and width are those\n",
    "        of the image unless use_mini_mask is True, in which case they are\n",
    "        defined in MINI_MASK_SHAPE.\n",
    "    \"\"\"\n",
    "    # Load image and mask\n",
    "    image = dataset.load_image(image_id)\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "    original_shape = image.shape\n",
    "    image, window, scale, padding, crop = utils.resize_image(\n",
    "        image,\n",
    "        min_dim=config.IMAGE_MIN_DIM,\n",
    "        min_scale=config.IMAGE_MIN_SCALE,\n",
    "        max_dim=config.IMAGE_MAX_DIM,\n",
    "        mode=config.IMAGE_RESIZE_MODE)\n",
    "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
    "\n",
    "    # Random horizontal flips.\n",
    "    # TODO: will be removed in a future update in favor of augmentation\n",
    "    if augment:\n",
    "        logging.warning(\"'augment' is deprecated. Use 'augmentation' instead.\")\n",
    "        if random.randint(0, 1):\n",
    "            image = np.fliplr(image)\n",
    "            mask = np.fliplr(mask)\n",
    "\n",
    "    # Augmentation\n",
    "    # This requires the imgaug lib (https://github.com/aleju/imgaug)\n",
    "    if augmentation:\n",
    "        import imgaug\n",
    "\n",
    "        # Augmenters that are safe to apply to masks\n",
    "        # Some, such as Affine, have settings that make them unsafe, so always\n",
    "        # test your augmentation on masks\n",
    "        MASK_AUGMENTERS = [\"Sequential\", \"SomeOf\", \"OneOf\", \"Sometimes\",\n",
    "                           \"Fliplr\", \"Flipud\", \"CropAndPad\",\n",
    "                           \"Affine\", \"PiecewiseAffine\"]\n",
    "\n",
    "        def hook(images, augmenter, parents, default):\n",
    "            \"\"\"Determines which augmenters to apply to masks.\"\"\"\n",
    "            return augmenter.__class__.__name__ in MASK_AUGMENTERS\n",
    "\n",
    "        # Store shapes before augmentation to compare\n",
    "        image_shape = image.shape\n",
    "        mask_shape = mask.shape\n",
    "        # Make augmenters deterministic to apply similarly to images and masks\n",
    "        det = augmentation.to_deterministic()\n",
    "        image = det.augment_image(image)\n",
    "        # Change mask to np.uint8 because imgaug doesn't support np.bool\n",
    "        mask = det.augment_image(mask.astype(np.uint8),\n",
    "                                 hooks=imgaug.HooksImages(activator=hook))\n",
    "        # Verify that shapes didn't change\n",
    "        assert image.shape == image_shape, \"Augmentation shouldn't change image size\"\n",
    "        assert mask.shape == mask_shape, \"Augmentation shouldn't change mask size\"\n",
    "        # Change mask back to bool\n",
    "        mask = mask.astype(np.bool)\n",
    "\n",
    "    # Note that some boxes might be all zeros if the corresponding mask got cropped out.\n",
    "    # and here is to filter them out\n",
    "    _idx = np.sum(mask, axis=(0, 1)) > 0\n",
    "    mask = mask[:, :, _idx]\n",
    "    class_ids = class_ids[_idx]\n",
    "    # Bounding boxes. Note that some boxes might be all zeros\n",
    "    # if the corresponding mask got cropped out.\n",
    "    # bbox: [num_instances, (y1, x1, y2, x2)]\n",
    "    bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "    # Active classes\n",
    "    # Different datasets have different classes, so track the\n",
    "    # classes supported in the dataset of this image.\n",
    "    active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)\n",
    "    source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][\"source\"]]\n",
    "    active_class_ids[source_class_ids] = 1\n",
    "\n",
    "    # Resize masks to smaller size to reduce memory usage\n",
    "    if use_mini_mask:\n",
    "        mask = utils.minimize_mask(bbox, mask, config.MINI_MASK_SHAPE)\n",
    "\n",
    "    # Image meta data\n",
    "    image_meta = compose_image_meta(image_id, original_shape, image.shape,\n",
    "                                    window, scale, active_class_ids)\n",
    "\n",
    "    return image, image_meta, class_ids, bbox, mask\n",
    "\n",
    "\n",
    "def compose_image_meta(image_id, original_image_shape, image_shape,\n",
    "                       window, scale, active_class_ids):\n",
    "    \"\"\"Takes attributes of an image and puts them in one 1D array.\n",
    "\n",
    "    image_id: An int ID of the image. Useful for debugging.\n",
    "    original_image_shape: [H, W, C] before resizing or padding.\n",
    "    image_shape: [H, W, C] after resizing and padding\n",
    "    window: (y1, x1, y2, x2) in pixels. The area of the image where the real\n",
    "            image is (excluding the padding)\n",
    "    scale: The scaling factor applied to the original image (float32)\n",
    "    active_class_ids: List of class_ids available in the dataset from which\n",
    "        the image came. Useful if training on images from multiple datasets\n",
    "        where not all classes are present in all datasets.\n",
    "    \"\"\"\n",
    "    meta = np.array(\n",
    "        [image_id] +                  # size=1\n",
    "        list(original_image_shape) +  # size=3\n",
    "        list(image_shape) +           # size=3\n",
    "        list(window) +                # size=4 (y1, x1, y2, x2) in image cooredinates\n",
    "        [scale] +                     # size=1\n",
    "        list(active_class_ids)        # size=num_classes\n",
    "    )\n",
    "    return meta\n",
    "\n",
    "\n",
    "def build_rpn_targets(image_shape, anchors, gt_class_ids, gt_boxes, config):\n",
    "    \"\"\"Given the anchors and GT boxes, compute overlaps and identify positive\n",
    "    anchors and deltas to refine them to match their corresponding GT boxes.\n",
    "\n",
    "    anchors: [num_anchors, (y1, x1, y2, x2)]\n",
    "    gt_class_ids: [num_gt_boxes] Integer class IDs.\n",
    "    gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)]\n",
    "\n",
    "    Returns:\n",
    "    rpn_match: [N] (int32) matches between anchors and GT boxes.\n",
    "               1 = positive anchor, -1 = negative anchor, 0 = neutral\n",
    "    rpn_bbox: [N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.\n",
    "    \"\"\"\n",
    "    # RPN Match: 1 = positive anchor, -1 = negative anchor, 0 = neutral\n",
    "    rpn_match = np.zeros([anchors.shape[0]], dtype=np.int32)\n",
    "    # RPN bounding boxes: [max anchors per image, (dy, dx, log(dh), log(dw))]\n",
    "    rpn_bbox = np.zeros((config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4))\n",
    "\n",
    "    # Handle COCO crowds\n",
    "    # A crowd box in COCO is a bounding box around several instances. Exclude\n",
    "    # them from training. A crowd box is given a negative class ID.\n",
    "    crowd_ix = np.where(gt_class_ids < 0)[0]\n",
    "    if crowd_ix.shape[0] > 0:\n",
    "        # Filter out crowds from ground truth class IDs and boxes\n",
    "        non_crowd_ix = np.where(gt_class_ids > 0)[0]\n",
    "        crowd_boxes = gt_boxes[crowd_ix]\n",
    "        gt_class_ids = gt_class_ids[non_crowd_ix]\n",
    "        gt_boxes = gt_boxes[non_crowd_ix]\n",
    "        # Compute overlaps with crowd boxes [anchors, crowds]\n",
    "        crowd_overlaps = utils.compute_overlaps(anchors, crowd_boxes)\n",
    "        crowd_iou_max = np.amax(crowd_overlaps, axis=1)\n",
    "        no_crowd_bool = (crowd_iou_max < 0.001)\n",
    "    else:\n",
    "        # All anchors don't intersect a crowd\n",
    "        no_crowd_bool = np.ones([anchors.shape[0]], dtype=bool)\n",
    "\n",
    "    # Compute overlaps [num_anchors, num_gt_boxes]\n",
    "    overlaps = utils.compute_overlaps(anchors, gt_boxes)\n",
    "\n",
    "    # Match anchors to GT Boxes\n",
    "    # If an anchor overlaps a GT box with IoU >= 0.7 then it's positive.\n",
    "    # If an anchor overlaps a GT box with IoU < 0.3 then it's negative.\n",
    "    # Neutral anchors are those that don't match the conditions above,\n",
    "    # and they don't influence the loss function.\n",
    "    # However, don't keep any GT box unmatched (rare, but happens). Instead,\n",
    "    # match it to the closest anchor (even if its max IoU is < 0.3).\n",
    "    #\n",
    "    # 1. Set negative anchors first. They get overwritten below if a GT box is\n",
    "    # matched to them. Skip boxes in crowd areas.\n",
    "    anchor_iou_argmax = np.argmax(overlaps, axis=1)\n",
    "    anchor_iou_max = overlaps[np.arange(overlaps.shape[0]), anchor_iou_argmax]\n",
    "    rpn_match[(anchor_iou_max < 0.3) & (no_crowd_bool)] = -1\n",
    "    # 2. Set an anchor for each GT box (regardless of IoU value).\n",
    "    # If multiple anchors have the same IoU match all of them\n",
    "    gt_iou_argmax = np.argwhere(overlaps == np.max(overlaps, axis=0))[:,0]\n",
    "    rpn_match[gt_iou_argmax] = 1\n",
    "    # 3. Set anchors with high overlap as positive.\n",
    "    rpn_match[anchor_iou_max >= 0.7] = 1\n",
    "\n",
    "    # Subsample to balance positive and negative anchors\n",
    "    # Don't let positives be more than half the anchors\n",
    "    ids = np.where(rpn_match == 1)[0]\n",
    "    extra = len(ids) - (config.RPN_TRAIN_ANCHORS_PER_IMAGE // 2)\n",
    "    if extra > 0:\n",
    "        # Reset the extra ones to neutral\n",
    "        ids = np.random.choice(ids, extra, replace=False)\n",
    "        rpn_match[ids] = 0\n",
    "    # Same for negative proposals\n",
    "    ids = np.where(rpn_match == -1)[0]\n",
    "    extra = len(ids) - (config.RPN_TRAIN_ANCHORS_PER_IMAGE -\n",
    "                        np.sum(rpn_match == 1))\n",
    "    if extra > 0:\n",
    "        # Rest the extra ones to neutral\n",
    "        ids = np.random.choice(ids, extra, replace=False)\n",
    "        rpn_match[ids] = 0\n",
    "\n",
    "    # For positive anchors, compute shift and scale needed to transform them\n",
    "    # to match the corresponding GT boxes.\n",
    "    ids = np.where(rpn_match == 1)[0]\n",
    "    ix = 0  # index into rpn_bbox\n",
    "    # TODO: use box_refinement() rather than duplicating the code here\n",
    "    for i, a in zip(ids, anchors[ids]):\n",
    "        # Closest gt box (it might have IoU < 0.7)\n",
    "        gt = gt_boxes[anchor_iou_argmax[i]]\n",
    "\n",
    "        # Convert coordinates to center plus width/height.\n",
    "        # GT Box\n",
    "        gt_h = gt[2] - gt[0]\n",
    "        gt_w = gt[3] - gt[1]\n",
    "        gt_center_y = gt[0] + 0.5 * gt_h\n",
    "        gt_center_x = gt[1] + 0.5 * gt_w\n",
    "        # Anchor\n",
    "        a_h = a[2] - a[0]\n",
    "        a_w = a[3] - a[1]\n",
    "        a_center_y = a[0] + 0.5 * a_h\n",
    "        a_center_x = a[1] + 0.5 * a_w\n",
    "\n",
    "        # Compute the bbox refinement that the RPN should predict.\n",
    "        rpn_bbox[ix] = [\n",
    "            (gt_center_y - a_center_y) / a_h,\n",
    "            (gt_center_x - a_center_x) / a_w,\n",
    "            np.log(gt_h / a_h),\n",
    "            np.log(gt_w / a_w),\n",
    "        ]\n",
    "        # Normalize\n",
    "        rpn_bbox[ix] /= config.RPN_BBOX_STD_DEV\n",
    "        ix += 1\n",
    "\n",
    "    return rpn_match, rpn_bbox\n",
    "\n",
    "def mold_image(images, config):\n",
    "    \"\"\"Expects an RGB image (or array of images) and subtracts\n",
    "    the mean pixel and converts it to float. Expects image\n",
    "    colors in RGB order.\n",
    "    \"\"\"\n",
    "    return images.astype(np.float32) - config.MEAN_PIXEL\n",
    "\n",
    "import logging\n",
    "a = data_generator(dataset_train, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58fd6fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f3ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
